{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                0.00\n",
       "MSSubClass        0.00\n",
       "MSZoning          0.00\n",
       "LotFrontage      17.74\n",
       "LotArea           0.00\n",
       "                 ...  \n",
       "MoSold            0.00\n",
       "YrSold            0.00\n",
       "SaleType          0.00\n",
       "SaleCondition     0.00\n",
       "SalePrice         0.00\n",
       "Length: 81, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here first i have checked the percentage of missing values\n",
    "# as we can see our training data here some of the features contain more than 70 % missing values, so better to drop them\n",
    "\n",
    "\n",
    "round((train.isnull().sum()/len(train)*100),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x27a8e5089b0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(train.isnull(),yticklabels=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treating missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### droping columns where missing values are more than 70% and which does not have any impact on target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['Id','Alley','GarageYrBlt','PoolQC','Fence','MiscFeature'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### here i have run a for loop in our data set columns where type of values are categorical, this function will be fill missing value by mode() of that particular column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1          20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "\n",
       "  Utilities LotConfig LandSlope  ... EnclosedPorch 3SsnPorch ScreenPorch  \\\n",
       "0    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "1    AllPub       FR2       Gtl  ...             0         0           0   \n",
       "\n",
       "  PoolArea MiscVal  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
       "0        0       0       2    2008        WD         Normal    208500  \n",
       "1        0       0       5    2007        WD         Normal    181500  \n",
       "\n",
       "[2 rows x 75 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for column in train.columns:\n",
    "    if train[column].dtype == type('int64'):\n",
    "        train[column] = train[column].fillna(train[column].mean())\n",
    "        \n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1          20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "\n",
       "  Utilities LotConfig LandSlope  ... EnclosedPorch 3SsnPorch ScreenPorch  \\\n",
       "0    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "1    AllPub       FR2       Gtl  ...             0         0           0   \n",
       "\n",
       "  PoolArea MiscVal  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
       "0        0       0       2    2008        WD         Normal    208500  \n",
       "1        0       0       5    2007        WD         Normal    181500  \n",
       "\n",
       "[2 rows x 75 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for column in train.columns:\n",
    "    if train[column].dtype == type(object):\n",
    "        train[column] = train[column].fillna(train[column].mode()[0])\n",
    "        \n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### columns containing float values will be filled by mean() value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['LotFrontage']=train['LotFrontage'].fillna(train['LotFrontage'].mean())\n",
    "\n",
    "train['MasVnrArea']=train['MasVnrArea'].fillna(train['MasVnrArea'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### now plotting heatmap to check no. of remaning missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x27a956a2ba8>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(train.isnull(),yticklabels=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['MSZoning','Street','LotShape','LandContour','Utilities','LotConfig','LandSlope','Neighborhood',\n",
    "         'Condition2','BldgType','Condition1','HouseStyle','SaleType',\n",
    "        'SaleCondition','ExterCond',\n",
    "         'ExterQual','Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n",
    "        'RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','Heating','HeatingQC',\n",
    "         'CentralAir',\n",
    "         'Electrical','KitchenQual','Functional',\n",
    "         'FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_onehot_multcols(multcolumns):\n",
    "    df_final=final_df\n",
    "    i=0\n",
    "    for fields in multcolumns:\n",
    "        \n",
    "        print(fields)\n",
    "        df1=pd.get_dummies(final_df[fields],drop_first=True)\n",
    "        \n",
    "        final_df.drop([fields],axis=1,inplace=True)\n",
    "        if i==0:\n",
    "            df_final=df1.copy()\n",
    "        else:\n",
    "            \n",
    "            df_final=pd.concat([df_final,df1],axis=1)\n",
    "        i=i+1\n",
    "       \n",
    "        \n",
    "    df_final=pd.concat([final_df,df_final],axis=1)\n",
    "        \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df=train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.read_csv('newtest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sachin\\.conda\\envs\\tensorflow1\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "final_df=pd.concat([train,test_df],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning\n",
      "Street\n",
      "LotShape\n",
      "LandContour\n",
      "Utilities\n",
      "LotConfig\n",
      "LandSlope\n",
      "Neighborhood\n",
      "Condition2\n",
      "BldgType\n",
      "Condition1\n",
      "HouseStyle\n",
      "SaleType\n",
      "SaleCondition\n",
      "ExterCond\n",
      "ExterQual\n",
      "Foundation\n",
      "BsmtQual\n",
      "BsmtCond\n",
      "BsmtExposure\n",
      "BsmtFinType1\n",
      "BsmtFinType2\n",
      "RoofStyle\n",
      "RoofMatl\n",
      "Exterior1st\n",
      "Exterior2nd\n",
      "MasVnrType\n",
      "Heating\n",
      "HeatingQC\n",
      "CentralAir\n",
      "Electrical\n",
      "KitchenQual\n",
      "Functional\n",
      "FireplaceQu\n",
      "GarageType\n",
      "GarageFinish\n",
      "GarageQual\n",
      "GarageCond\n",
      "PavedDrive\n"
     ]
    }
   ],
   "source": [
    "final_df=category_onehot_multcols(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df =final_df.loc[:,~final_df.columns.duplicated()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>272</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       856       854          0             3       706.0         0.0   \n",
       "1      1262         0          0             3       978.0         0.0   \n",
       "2       920       866          0             3       486.0         0.0   \n",
       "3       961       756          0             3       216.0         0.0   \n",
       "4      1145      1053          0             4       655.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch  ...  Min1  Min2  Typ  \\\n",
       "0           1.0           0.0      150.0              0  ...     0     0    1   \n",
       "1           0.0           1.0      284.0              0  ...     0     0    1   \n",
       "2           1.0           0.0      434.0              0  ...     0     0    1   \n",
       "3           1.0           0.0      540.0            272  ...     0     0    1   \n",
       "4           1.0           0.0      490.0              0  ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    1  0  \n",
       "1       1        0        0        0       0    1  0  \n",
       "2       1        0        0        0       0    1  0  \n",
       "3       0        0        0        0       1    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 176 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train = final_df.iloc[:1422,:]\n",
    "df_Test = final_df.iloc[1422:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_Train.drop(['SalePrice'],axis=1)\n",
    "y_train=df_Train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sachin\\.conda\\envs\\tensorflow1\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=175, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\sachin\\.conda\\envs\\tensorflow1\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  \n",
      "C:\\Users\\sachin\\.conda\\envs\\tensorflow1\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\sachin\\.conda\\envs\\tensorflow1\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  del sys.path[0]\n",
      "C:\\Users\\sachin\\.conda\\envs\\tensorflow1\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1137 samples, validate on 285 samples\n",
      "Epoch 1/1200\n",
      "1137/1137 [==============================] - 2s 2ms/step - loss: 167145.5443 - val_loss: 88993.3388\n",
      "Epoch 2/1200\n",
      "1137/1137 [==============================] - 1s 512us/step - loss: 74136.1744 - val_loss: 65858.6690\n",
      "Epoch 3/1200\n",
      "1137/1137 [==============================] - 1s 537us/step - loss: 67733.8839 - val_loss: 62870.6761\n",
      "Epoch 4/1200\n",
      "1137/1137 [==============================] - 1s 591us/step - loss: 63269.1799 - val_loss: 60449.6096\n",
      "Epoch 5/1200\n",
      "1137/1137 [==============================] - 1s 601us/step - loss: 59769.6243 - val_loss: 58218.9403\n",
      "Epoch 6/1200\n",
      "1137/1137 [==============================] - 1s 549us/step - loss: 56916.2355 - val_loss: 55869.9071\n",
      "Epoch 7/1200\n",
      "1137/1137 [==============================] - 1s 609us/step - loss: 53211.4082 - val_loss: 53772.3762\n",
      "Epoch 8/1200\n",
      "1137/1137 [==============================] - 1s 567us/step - loss: 50723.2639 - val_loss: 51931.7144\n",
      "Epoch 9/1200\n",
      "1137/1137 [==============================] - 1s 599us/step - loss: 48311.8597 - val_loss: 49925.6484\n",
      "Epoch 10/1200\n",
      "1137/1137 [==============================] - 1s 593us/step - loss: 44423.0337 - val_loss: 48218.2512\n",
      "Epoch 11/1200\n",
      "1137/1137 [==============================] - 1s 530us/step - loss: 42814.9919 - val_loss: 47064.9666\n",
      "Epoch 12/1200\n",
      "1137/1137 [==============================] - 1s 568us/step - loss: 40819.9204 - val_loss: 46162.9120\n",
      "Epoch 13/1200\n",
      "1137/1137 [==============================] - 1s 552us/step - loss: 39323.9435 - val_loss: 45044.6430\n",
      "Epoch 14/1200\n",
      "1137/1137 [==============================] - 1s 583us/step - loss: 38257.0485 - val_loss: 44688.3674\n",
      "Epoch 15/1200\n",
      "1137/1137 [==============================] - 1s 558us/step - loss: 36927.2458 - val_loss: 44568.1189\n",
      "Epoch 16/1200\n",
      "1137/1137 [==============================] - 1s 601us/step - loss: 37294.5612 - val_loss: 44328.1294\n",
      "Epoch 17/1200\n",
      "1137/1137 [==============================] - 1s 568us/step - loss: 36905.0982 - val_loss: 44769.3028\n",
      "Epoch 18/1200\n",
      "1137/1137 [==============================] - 1s 543us/step - loss: 36420.2649 - val_loss: 44451.3743\n",
      "Epoch 19/1200\n",
      "1137/1137 [==============================] - 1s 600us/step - loss: 36374.1149 - val_loss: 44812.2564\n",
      "Epoch 20/1200\n",
      "1137/1137 [==============================] - 1s 564us/step - loss: 36332.7825 - val_loss: 45145.0792\n",
      "Epoch 21/1200\n",
      "1137/1137 [==============================] - 1s 604us/step - loss: 36294.7167 - val_loss: 44593.9788\n",
      "Epoch 22/1200\n",
      "1137/1137 [==============================] - 1s 557us/step - loss: 35769.7666 - val_loss: 44655.8775\n",
      "Epoch 23/1200\n",
      "1137/1137 [==============================] - 1s 575us/step - loss: 35815.0742 - val_loss: 44890.4440\n",
      "Epoch 24/1200\n",
      "1137/1137 [==============================] - 1s 551us/step - loss: 35905.9441 - val_loss: 45598.1995\n",
      "Epoch 25/1200\n",
      "1137/1137 [==============================] - 1s 565us/step - loss: 35828.7129 - val_loss: 44110.5026\n",
      "Epoch 26/1200\n",
      "1137/1137 [==============================] - 1s 610us/step - loss: 36000.7015 - val_loss: 44468.5467\n",
      "Epoch 27/1200\n",
      "1137/1137 [==============================] - 1s 614us/step - loss: 35510.3540 - val_loss: 43864.4930\n",
      "Epoch 28/1200\n",
      "1137/1137 [==============================] - 1s 604us/step - loss: 35473.5288 - val_loss: 44551.8239\n",
      "Epoch 29/1200\n",
      "1137/1137 [==============================] - 1s 551us/step - loss: 35654.5415 - val_loss: 44041.1282\n",
      "Epoch 30/1200\n",
      "1137/1137 [==============================] - 1s 610us/step - loss: 35798.3857 - val_loss: 44963.5217\n",
      "Epoch 31/1200\n",
      "1137/1137 [==============================] - 1s 553us/step - loss: 35415.4707 - val_loss: 43900.4320\n",
      "Epoch 32/1200\n",
      "1137/1137 [==============================] - 1s 579us/step - loss: 35372.2225 - val_loss: 43966.0159\n",
      "Epoch 33/1200\n",
      "1137/1137 [==============================] - 1s 549us/step - loss: 35390.5142 - val_loss: 44738.8543\n",
      "Epoch 34/1200\n",
      "1137/1137 [==============================] - 1s 594us/step - loss: 35247.5318 - val_loss: 43810.7129\n",
      "Epoch 35/1200\n",
      "1137/1137 [==============================] - 1s 553us/step - loss: 35922.4202 - val_loss: 44738.3665\n",
      "Epoch 36/1200\n",
      "1137/1137 [==============================] - 1s 554us/step - loss: 35146.8411 - val_loss: 44096.8511\n",
      "Epoch 37/1200\n",
      "1137/1137 [==============================] - 1s 594us/step - loss: 35103.2647 - val_loss: 46009.2378\n",
      "Epoch 38/1200\n",
      "1137/1137 [==============================] - 1s 573us/step - loss: 35196.5976 - val_loss: 43610.1405\n",
      "Epoch 39/1200\n",
      "1137/1137 [==============================] - 1s 607us/step - loss: 34615.5625 - val_loss: 43700.8372\n",
      "Epoch 40/1200\n",
      "1137/1137 [==============================] - 1s 547us/step - loss: 34613.3406 - val_loss: 43694.5903\n",
      "Epoch 41/1200\n",
      "1137/1137 [==============================] - 1s 566us/step - loss: 34578.3406 - val_loss: 43939.3826\n",
      "Epoch 42/1200\n",
      "1137/1137 [==============================] - 1s 574us/step - loss: 34787.2088 - val_loss: 43807.5340\n",
      "Epoch 43/1200\n",
      "1137/1137 [==============================] - 1s 583us/step - loss: 34456.8767 - val_loss: 43481.1425\n",
      "Epoch 44/1200\n",
      "1137/1137 [==============================] - 1s 544us/step - loss: 34393.4983 - val_loss: 43515.2176\n",
      "Epoch 45/1200\n",
      "1137/1137 [==============================] - 1s 624us/step - loss: 34538.9507 - val_loss: 43684.6991\n",
      "Epoch 46/1200\n",
      "1137/1137 [==============================] - 1s 625us/step - loss: 34084.4736 - val_loss: 43647.6982\n",
      "Epoch 47/1200\n",
      "1137/1137 [==============================] - 1s 589us/step - loss: 34178.3366 - val_loss: 43736.8478\n",
      "Epoch 48/1200\n",
      "1137/1137 [==============================] - 1s 627us/step - loss: 34139.6447 - val_loss: 43734.7677\n",
      "Epoch 49/1200\n",
      "1137/1137 [==============================] - 1s 607us/step - loss: 34104.3883 - val_loss: 43539.7291\n",
      "Epoch 50/1200\n",
      "1137/1137 [==============================] - 1s 617us/step - loss: 34228.2400 - val_loss: 43672.0199\n",
      "Epoch 51/1200\n",
      "1137/1137 [==============================] - 1s 613us/step - loss: 34261.3865 - val_loss: 44082.1998\n",
      "Epoch 52/1200\n",
      "1137/1137 [==============================] - 1s 623us/step - loss: 34240.5648 - val_loss: 43672.1172\n",
      "Epoch 53/1200\n",
      "1137/1137 [==============================] - 1s 604us/step - loss: 34109.2982 - val_loss: 45423.0050\n",
      "Epoch 54/1200\n",
      "1137/1137 [==============================] - 1s 613us/step - loss: 34259.3160 - val_loss: 44604.1013\n",
      "Epoch 55/1200\n",
      "1137/1137 [==============================] - 1s 609us/step - loss: 33926.7246 - val_loss: 43554.7018\n",
      "Epoch 56/1200\n",
      "1137/1137 [==============================] - 1s 611us/step - loss: 33833.6201 - val_loss: 44224.8460\n",
      "Epoch 57/1200\n",
      "1137/1137 [==============================] - 1s 615us/step - loss: 33639.4171 - val_loss: 44276.7732\n",
      "Epoch 58/1200\n",
      "1137/1137 [==============================] - 1s 597us/step - loss: 33638.5176 - val_loss: 43436.2497\n",
      "Epoch 59/1200\n",
      "1137/1137 [==============================] - 1s 615us/step - loss: 33970.7697 - val_loss: 43765.3082\n",
      "Epoch 60/1200\n",
      "1137/1137 [==============================] - 1s 610us/step - loss: 33500.5200 - val_loss: 43780.0550\n",
      "Epoch 61/1200\n",
      "1137/1137 [==============================] - 1s 601us/step - loss: 33406.0241 - val_loss: 43658.0995\n",
      "Epoch 62/1200\n",
      "1137/1137 [==============================] - 1s 616us/step - loss: 33051.9741 - val_loss: 43633.0068\n",
      "Epoch 63/1200\n",
      "1137/1137 [==============================] - 1s 589us/step - loss: 33402.3530 - val_loss: 44171.8340\n",
      "Epoch 64/1200\n",
      "1137/1137 [==============================] - 1s 615us/step - loss: 33685.5571 - val_loss: 43682.8957\n",
      "Epoch 65/1200\n",
      "1137/1137 [==============================] - 1s 602us/step - loss: 32882.2886 - val_loss: 43313.9274\n",
      "Epoch 66/1200\n",
      "1137/1137 [==============================] - 1s 618us/step - loss: 32678.5075 - val_loss: 43694.7181\n",
      "Epoch 67/1200\n",
      "1137/1137 [==============================] - 1s 603us/step - loss: 33093.1378 - val_loss: 44139.3835\n",
      "Epoch 68/1200\n",
      "1137/1137 [==============================] - 1s 615us/step - loss: 32711.0751 - val_loss: 43834.0783\n",
      "Epoch 69/1200\n",
      "1137/1137 [==============================] - 1s 604us/step - loss: 33580.3206 - val_loss: 43390.9883\n",
      "Epoch 70/1200\n",
      "1137/1137 [==============================] - 1s 610us/step - loss: 33058.0443 - val_loss: 43747.8684\n",
      "Epoch 71/1200\n",
      "1137/1137 [==============================] - 1s 611us/step - loss: 32831.6757 - val_loss: 43745.6799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/1200\n",
      "1137/1137 [==============================] - 1s 549us/step - loss: 32743.9419 - val_loss: 45840.0109\n",
      "Epoch 73/1200\n",
      "1137/1137 [==============================] - 1s 518us/step - loss: 33358.7341 - val_loss: 43970.6653\n",
      "Epoch 74/1200\n",
      "1137/1137 [==============================] - 1s 523us/step - loss: 32607.2111 - val_loss: 43742.5395\n",
      "Epoch 75/1200\n",
      "1137/1137 [==============================] - 1s 520us/step - loss: 32800.3099 - val_loss: 43751.9289\n",
      "Epoch 76/1200\n",
      "1137/1137 [==============================] - 1s 551us/step - loss: 32438.4881 - val_loss: 46710.0573\n",
      "Epoch 77/1200\n",
      "1137/1137 [==============================] - 1s 551us/step - loss: 32300.6192 - val_loss: 43697.8658\n",
      "Epoch 78/1200\n",
      "1137/1137 [==============================] - 1s 545us/step - loss: 32119.5190 - val_loss: 43969.4293\n",
      "Epoch 79/1200\n",
      "1137/1137 [==============================] - 1s 526us/step - loss: 32260.0147 - val_loss: 43691.3108\n",
      "Epoch 80/1200\n",
      "1137/1137 [==============================] - 1s 556us/step - loss: 32168.4727 - val_loss: 44513.2258\n",
      "Epoch 81/1200\n",
      "1137/1137 [==============================] - 1s 593us/step - loss: 32496.4960 - val_loss: 45376.7547\n",
      "Epoch 82/1200\n",
      "1137/1137 [==============================] - 1s 534us/step - loss: 32061.6236 - val_loss: 43764.5948\n",
      "Epoch 83/1200\n",
      "1137/1137 [==============================] - 1s 528us/step - loss: 31986.3244 - val_loss: 46422.8906\n",
      "Epoch 84/1200\n",
      "1137/1137 [==============================] - 1s 572us/step - loss: 32150.1616 - val_loss: 44605.4240\n",
      "Epoch 85/1200\n",
      "1137/1137 [==============================] - 1s 580us/step - loss: 32292.9264 - val_loss: 44566.4652\n",
      "Epoch 86/1200\n",
      "1137/1137 [==============================] - 1s 520us/step - loss: 32022.2453 - val_loss: 43704.6020\n",
      "Epoch 87/1200\n",
      "1137/1137 [==============================] - 1s 525us/step - loss: 31906.0578 - val_loss: 44867.0016\n",
      "Epoch 88/1200\n",
      "1137/1137 [==============================] - 1s 550us/step - loss: 32032.8949 - val_loss: 43644.0566\n",
      "Epoch 89/1200\n",
      "1137/1137 [==============================] - 1s 572us/step - loss: 32166.9850 - val_loss: 44300.6112\n",
      "Epoch 90/1200\n",
      "1137/1137 [==============================] - 1s 548us/step - loss: 31902.7921 - val_loss: 44105.6463\n",
      "Epoch 91/1200\n",
      "1137/1137 [==============================] - 1s 521us/step - loss: 31882.7095 - val_loss: 43651.7122\n",
      "Epoch 92/1200\n",
      "1137/1137 [==============================] - 1s 568us/step - loss: 32021.7041 - val_loss: 44414.5023\n",
      "Epoch 93/1200\n",
      "1137/1137 [==============================] - 1s 542us/step - loss: 31651.9619 - val_loss: 44079.3492\n",
      "Epoch 94/1200\n",
      "1137/1137 [==============================] - 1s 582us/step - loss: 32136.9617 - val_loss: 44125.6263\n",
      "Epoch 95/1200\n",
      "1137/1137 [==============================] - 1s 542us/step - loss: 32005.8632 - val_loss: 43649.9073\n",
      "Epoch 96/1200\n",
      "1137/1137 [==============================] - 1s 554us/step - loss: 31754.4542 - val_loss: 43673.7552\n",
      "Epoch 97/1200\n",
      "1137/1137 [==============================] - 1s 530us/step - loss: 32123.3444 - val_loss: 43814.3146\n",
      "Epoch 98/1200\n",
      "1137/1137 [==============================] - 1s 549us/step - loss: 32076.3004 - val_loss: 44195.6627\n",
      "Epoch 99/1200\n",
      "1137/1137 [==============================] - 1s 549us/step - loss: 30587.9736 - val_loss: 43923.5848\n",
      "Epoch 100/1200\n",
      "1137/1137 [==============================] - 1s 589us/step - loss: 31810.8066 - val_loss: 43802.7794\n",
      "Epoch 101/1200\n",
      "1137/1137 [==============================] - 1s 552us/step - loss: 31296.1579 - val_loss: 45119.2710\n",
      "Epoch 102/1200\n",
      "1137/1137 [==============================] - 1s 581us/step - loss: 31548.5696 - val_loss: 43614.2395\n",
      "Epoch 103/1200\n",
      "1137/1137 [==============================] - 1s 592us/step - loss: 31366.6835 - val_loss: 44102.2902\n",
      "Epoch 104/1200\n",
      "1137/1137 [==============================] - 1s 541us/step - loss: 31550.5968 - val_loss: 44836.4413\n",
      "Epoch 105/1200\n",
      "1137/1137 [==============================] - 1s 548us/step - loss: 31512.2676 - val_loss: 43731.2878\n",
      "Epoch 106/1200\n",
      "1137/1137 [==============================] - 1s 568us/step - loss: 31041.7490 - val_loss: 44216.5270\n",
      "Epoch 107/1200\n",
      "1137/1137 [==============================] - 1s 562us/step - loss: 31515.1629 - val_loss: 44680.2405\n",
      "Epoch 108/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 31968.2678 - val_loss: 45449.1393\n",
      "Epoch 109/1200\n",
      "1137/1137 [==============================] - 1s 546us/step - loss: 31482.3358 - val_loss: 45739.7775\n",
      "Epoch 110/1200\n",
      "1137/1137 [==============================] - 1s 575us/step - loss: 31262.1996 - val_loss: 44282.8038\n",
      "Epoch 111/1200\n",
      "1137/1137 [==============================] - 1s 590us/step - loss: 31488.0373 - val_loss: 44284.6719\n",
      "Epoch 112/1200\n",
      "1137/1137 [==============================] - 1s 598us/step - loss: 31175.8662 - val_loss: 43989.4663\n",
      "Epoch 113/1200\n",
      "1137/1137 [==============================] - 1s 582us/step - loss: 31250.4528 - val_loss: 44484.9126\n",
      "Epoch 114/1200\n",
      "1137/1137 [==============================] - 1s 588us/step - loss: 31237.7032 - val_loss: 44697.9892\n",
      "Epoch 115/1200\n",
      "1137/1137 [==============================] - 1s 545us/step - loss: 31374.7792 - val_loss: 43917.2771\n",
      "Epoch 116/1200\n",
      "1137/1137 [==============================] - 1s 565us/step - loss: 31626.1816 - val_loss: 44282.8787\n",
      "Epoch 117/1200\n",
      "1137/1137 [==============================] - 1s 585us/step - loss: 31235.3903 - val_loss: 44333.2750\n",
      "Epoch 118/1200\n",
      "1137/1137 [==============================] - 1s 570us/step - loss: 31061.1593 - val_loss: 44297.8150\n",
      "Epoch 119/1200\n",
      "1137/1137 [==============================] - 1s 522us/step - loss: 31026.1670 - val_loss: 43582.1355\n",
      "Epoch 120/1200\n",
      "1137/1137 [==============================] - 1s 524us/step - loss: 31185.1786 - val_loss: 44479.2195\n",
      "Epoch 121/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 30784.8188 - val_loss: 43742.9482\n",
      "Epoch 122/1200\n",
      "1137/1137 [==============================] - 1s 551us/step - loss: 31091.9279 - val_loss: 47602.9536\n",
      "Epoch 123/1200\n",
      "1137/1137 [==============================] - 1s 594us/step - loss: 31254.4710 - val_loss: 44976.6679\n",
      "Epoch 124/1200\n",
      "1137/1137 [==============================] - 1s 540us/step - loss: 31220.1394 - val_loss: 43602.6122\n",
      "Epoch 125/1200\n",
      "1137/1137 [==============================] - 1s 578us/step - loss: 31066.9136 - val_loss: 45364.7685\n",
      "Epoch 126/1200\n",
      "1137/1137 [==============================] - 1s 599us/step - loss: 30870.7457 - val_loss: 43498.3484\n",
      "Epoch 127/1200\n",
      "1137/1137 [==============================] - 1s 547us/step - loss: 31012.2516 - val_loss: 44083.3971\n",
      "Epoch 128/1200\n",
      "1137/1137 [==============================] - 1s 562us/step - loss: 31084.3143 - val_loss: 45342.3220\n",
      "Epoch 129/1200\n",
      "1137/1137 [==============================] - 1s 595us/step - loss: 30809.7877 - val_loss: 44819.9967\n",
      "Epoch 130/1200\n",
      "1137/1137 [==============================] - 1s 527us/step - loss: 30829.1655 - val_loss: 43942.4482\n",
      "Epoch 131/1200\n",
      "1137/1137 [==============================] - 1s 541us/step - loss: 30829.9124 - val_loss: 45354.9997\n",
      "Epoch 132/1200\n",
      "1137/1137 [==============================] - 1s 584us/step - loss: 31286.5066 - val_loss: 44691.9429\n",
      "Epoch 133/1200\n",
      "1137/1137 [==============================] - 1s 532us/step - loss: 30486.2629 - val_loss: 44431.2464\n",
      "Epoch 134/1200\n",
      "1137/1137 [==============================] - 1s 540us/step - loss: 30070.6486 - val_loss: 44706.6543\n",
      "Epoch 135/1200\n",
      "1137/1137 [==============================] - 1s 550us/step - loss: 30453.6802 - val_loss: 44355.1114\n",
      "Epoch 136/1200\n",
      "1137/1137 [==============================] - 1s 593us/step - loss: 30829.1681 - val_loss: 43652.2693\n",
      "Epoch 137/1200\n",
      "1137/1137 [==============================] - 1s 540us/step - loss: 30610.6864 - val_loss: 44511.3744\n",
      "Epoch 138/1200\n",
      "1137/1137 [==============================] - 1s 545us/step - loss: 30738.1463 - val_loss: 44201.2303\n",
      "Epoch 139/1200\n",
      "1137/1137 [==============================] - 1s 557us/step - loss: 30343.4865 - val_loss: 44003.5253\n",
      "Epoch 140/1200\n",
      "1137/1137 [==============================] - 1s 564us/step - loss: 30441.9012 - val_loss: 43790.6685\n",
      "Epoch 141/1200\n",
      "1137/1137 [==============================] - 1s 569us/step - loss: 30288.4774 - val_loss: 43391.5474\n",
      "Epoch 142/1200\n",
      "1137/1137 [==============================] - 1s 543us/step - loss: 30579.5099 - val_loss: 44845.8446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/1200\n",
      "1137/1137 [==============================] - 1s 577us/step - loss: 30070.6838 - val_loss: 43785.3718\n",
      "Epoch 144/1200\n",
      "1137/1137 [==============================] - 1s 562us/step - loss: 30423.4565 - val_loss: 43813.1603\n",
      "Epoch 145/1200\n",
      "1137/1137 [==============================] - 1s 588us/step - loss: 30469.4430 - val_loss: 43142.1094\n",
      "Epoch 146/1200\n",
      "1137/1137 [==============================] - 1s 574us/step - loss: 30328.6345 - val_loss: 45275.6153\n",
      "Epoch 147/1200\n",
      "1137/1137 [==============================] - 1s 581us/step - loss: 29983.5769 - val_loss: 44093.6018\n",
      "Epoch 148/1200\n",
      "1137/1137 [==============================] - 1s 530us/step - loss: 29790.2108 - val_loss: 43334.0836\n",
      "Epoch 149/1200\n",
      "1137/1137 [==============================] - 1s 522us/step - loss: 30285.2569 - val_loss: 43388.2650\n",
      "Epoch 150/1200\n",
      "1137/1137 [==============================] - 1s 526us/step - loss: 30266.1680 - val_loss: 43271.3420\n",
      "Epoch 151/1200\n",
      "1137/1137 [==============================] - 1s 528us/step - loss: 29761.7693 - val_loss: 44740.0262\n",
      "Epoch 152/1200\n",
      "1137/1137 [==============================] - 1s 536us/step - loss: 29961.4911 - val_loss: 44953.6012\n",
      "Epoch 153/1200\n",
      "1137/1137 [==============================] - 1s 530us/step - loss: 29810.0091 - val_loss: 44745.6940\n",
      "Epoch 154/1200\n",
      "1137/1137 [==============================] - 1s 536us/step - loss: 30225.8010 - val_loss: 43836.0209\n",
      "Epoch 155/1200\n",
      "1137/1137 [==============================] - 1s 557us/step - loss: 29799.2600 - val_loss: 43470.8876\n",
      "Epoch 156/1200\n",
      "1137/1137 [==============================] - 1s 582us/step - loss: 29343.5331 - val_loss: 42851.0537\n",
      "Epoch 157/1200\n",
      "1137/1137 [==============================] - 1s 554us/step - loss: 30240.4259 - val_loss: 43548.1208\n",
      "Epoch 158/1200\n",
      "1137/1137 [==============================] - 1s 591us/step - loss: 29609.3294 - val_loss: 43726.6052\n",
      "Epoch 159/1200\n",
      "1137/1137 [==============================] - 1s 542us/step - loss: 29503.7409 - val_loss: 42871.3642\n",
      "Epoch 160/1200\n",
      "1137/1137 [==============================] - 1s 563us/step - loss: 29527.6550 - val_loss: 43552.1671\n",
      "Epoch 161/1200\n",
      "1137/1137 [==============================] - 1s 589us/step - loss: 29691.3896 - val_loss: 43549.3003\n",
      "Epoch 162/1200\n",
      "1137/1137 [==============================] - 1s 544us/step - loss: 29507.3087 - val_loss: 43165.3892\n",
      "Epoch 163/1200\n",
      "1137/1137 [==============================] - 1s 525us/step - loss: 29876.9859 - val_loss: 43953.4904\n",
      "Epoch 164/1200\n",
      "1137/1137 [==============================] - 1s 523us/step - loss: 29616.6755 - val_loss: 44134.1451\n",
      "Epoch 165/1200\n",
      "1137/1137 [==============================] - 1s 549us/step - loss: 29505.9389 - val_loss: 43044.5112\n",
      "Epoch 166/1200\n",
      "1137/1137 [==============================] - 1s 552us/step - loss: 29303.9427 - val_loss: 42827.5158\n",
      "Epoch 167/1200\n",
      "1137/1137 [==============================] - 1s 546us/step - loss: 29836.4687 - val_loss: 43381.5055\n",
      "Epoch 168/1200\n",
      "1137/1137 [==============================] - 1s 555us/step - loss: 29583.8000 - val_loss: 42547.3206\n",
      "Epoch 169/1200\n",
      "1137/1137 [==============================] - 1s 575us/step - loss: 28990.4088 - val_loss: 43061.4324\n",
      "Epoch 170/1200\n",
      "1137/1137 [==============================] - 1s 536us/step - loss: 29115.3056 - val_loss: 46018.0636\n",
      "Epoch 171/1200\n",
      "1137/1137 [==============================] - 1s 567us/step - loss: 29421.6900 - val_loss: 42660.3801\n",
      "Epoch 172/1200\n",
      "1137/1137 [==============================] - 1s 555us/step - loss: 29676.6265 - val_loss: 42886.4265\n",
      "Epoch 173/1200\n",
      "1137/1137 [==============================] - 1s 582us/step - loss: 29653.2674 - val_loss: 43154.6546\n",
      "Epoch 174/1200\n",
      "1137/1137 [==============================] - 1s 525us/step - loss: 29180.8581 - val_loss: 44332.7570\n",
      "Epoch 175/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 28819.5569 - val_loss: 42713.5979\n",
      "Epoch 176/1200\n",
      "1137/1137 [==============================] - 1s 521us/step - loss: 28916.5357 - val_loss: 43121.2698\n",
      "Epoch 177/1200\n",
      "1137/1137 [==============================] - 1s 556us/step - loss: 29121.6060 - val_loss: 43948.3341\n",
      "Epoch 178/1200\n",
      "1137/1137 [==============================] - 1s 537us/step - loss: 29137.0312 - val_loss: 43876.8377\n",
      "Epoch 179/1200\n",
      "1137/1137 [==============================] - 1s 538us/step - loss: 28870.0934 - val_loss: 42535.0645\n",
      "Epoch 180/1200\n",
      "1137/1137 [==============================] - 1s 533us/step - loss: 29020.7888 - val_loss: 42386.5185\n",
      "Epoch 181/1200\n",
      "1137/1137 [==============================] - 1s 521us/step - loss: 29422.7483 - val_loss: 42821.3765\n",
      "Epoch 182/1200\n",
      "1137/1137 [==============================] - 1s 523us/step - loss: 29115.0781 - val_loss: 43979.4823\n",
      "Epoch 183/1200\n",
      "1137/1137 [==============================] - 1s 525us/step - loss: 28664.6786 - val_loss: 42761.6803\n",
      "Epoch 184/1200\n",
      "1137/1137 [==============================] - 1s 542us/step - loss: 29115.7439 - val_loss: 43026.8183\n",
      "Epoch 185/1200\n",
      "1137/1137 [==============================] - 1s 536us/step - loss: 28797.1425 - val_loss: 42988.2788\n",
      "Epoch 186/1200\n",
      "1137/1137 [==============================] - 1s 529us/step - loss: 28826.8613 - val_loss: 42303.2121\n",
      "Epoch 187/1200\n",
      "1137/1137 [==============================] - 1s 571us/step - loss: 28543.3781 - val_loss: 42465.0491\n",
      "Epoch 188/1200\n",
      "1137/1137 [==============================] - 1s 514us/step - loss: 28815.1437 - val_loss: 42953.5700\n",
      "Epoch 189/1200\n",
      "1137/1137 [==============================] - 1s 569us/step - loss: 28240.6894 - val_loss: 42889.7120\n",
      "Epoch 190/1200\n",
      "1137/1137 [==============================] - 1s 545us/step - loss: 28493.1986 - val_loss: 42886.3832\n",
      "Epoch 191/1200\n",
      "1137/1137 [==============================] - 1s 540us/step - loss: 29202.3883 - val_loss: 42880.7652\n",
      "Epoch 192/1200\n",
      "1137/1137 [==============================] - 1s 574us/step - loss: 28277.5111 - val_loss: 42627.2455\n",
      "Epoch 193/1200\n",
      "1137/1137 [==============================] - 1s 531us/step - loss: 28404.1058 - val_loss: 42411.6628\n",
      "Epoch 194/1200\n",
      "1137/1137 [==============================] - 1s 526us/step - loss: 28207.6741 - val_loss: 41751.0609\n",
      "Epoch 195/1200\n",
      "1137/1137 [==============================] - 1s 546us/step - loss: 28197.3368 - val_loss: 42952.4874\n",
      "Epoch 196/1200\n",
      "1137/1137 [==============================] - 1s 554us/step - loss: 28445.6296 - val_loss: 43121.4040\n",
      "Epoch 197/1200\n",
      "1137/1137 [==============================] - 1s 571us/step - loss: 28535.7526 - val_loss: 42109.3258\n",
      "Epoch 198/1200\n",
      "1137/1137 [==============================] - 1s 580us/step - loss: 27968.8843 - val_loss: 42938.8936\n",
      "Epoch 199/1200\n",
      "1137/1137 [==============================] - 1s 546us/step - loss: 28246.0536 - val_loss: 45093.1151\n",
      "Epoch 200/1200\n",
      "1137/1137 [==============================] - 1s 596us/step - loss: 28374.5313 - val_loss: 41697.7021\n",
      "Epoch 201/1200\n",
      "1137/1137 [==============================] - 1s 597us/step - loss: 28066.5511 - val_loss: 42290.9363\n",
      "Epoch 202/1200\n",
      "1137/1137 [==============================] - 1s 596us/step - loss: 27822.8283 - val_loss: 42238.7361\n",
      "Epoch 203/1200\n",
      "1137/1137 [==============================] - 1s 580us/step - loss: 28328.0091 - val_loss: 42502.3265\n",
      "Epoch 204/1200\n",
      "1137/1137 [==============================] - 1s 550us/step - loss: 28061.1088 - val_loss: 42120.4070\n",
      "Epoch 205/1200\n",
      "1137/1137 [==============================] - 1s 516us/step - loss: 27559.6422 - val_loss: 41752.9512\n",
      "Epoch 206/1200\n",
      "1137/1137 [==============================] - 1s 540us/step - loss: 27677.4814 - val_loss: 41950.4561\n",
      "Epoch 207/1200\n",
      "1137/1137 [==============================] - 1s 589us/step - loss: 27853.6953 - val_loss: 41953.3737\n",
      "Epoch 208/1200\n",
      "1137/1137 [==============================] - 1s 543us/step - loss: 27587.0760 - val_loss: 42439.6139\n",
      "Epoch 209/1200\n",
      "1137/1137 [==============================] - 1s 548us/step - loss: 27510.4393 - val_loss: 44981.7466\n",
      "Epoch 210/1200\n",
      "1137/1137 [==============================] - 1s 555us/step - loss: 27520.8383 - val_loss: 41280.0556\n",
      "Epoch 211/1200\n",
      "1137/1137 [==============================] - 1s 527us/step - loss: 28013.2225 - val_loss: 41198.0528\n",
      "Epoch 212/1200\n",
      "1137/1137 [==============================] - 1s 561us/step - loss: 27632.2137 - val_loss: 41680.9000\n",
      "Epoch 213/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 1s 575us/step - loss: 27870.0506 - val_loss: 42151.6638\n",
      "Epoch 214/1200\n",
      "1137/1137 [==============================] - 1s 567us/step - loss: 27610.3570 - val_loss: 42680.8707\n",
      "Epoch 215/1200\n",
      "1137/1137 [==============================] - 1s 580us/step - loss: 27755.9337 - val_loss: 42153.6633\n",
      "Epoch 216/1200\n",
      "1137/1137 [==============================] - 1s 523us/step - loss: 27374.6472 - val_loss: 41190.2820\n",
      "Epoch 217/1200\n",
      "1137/1137 [==============================] - 1s 525us/step - loss: 27699.9286 - val_loss: 41255.1598\n",
      "Epoch 218/1200\n",
      "1137/1137 [==============================] - 1s 530us/step - loss: 27035.4521 - val_loss: 41495.7274\n",
      "Epoch 219/1200\n",
      "1137/1137 [==============================] - 1s 525us/step - loss: 27410.9984 - val_loss: 42613.7175\n",
      "Epoch 220/1200\n",
      "1137/1137 [==============================] - 1s 556us/step - loss: 27575.1659 - val_loss: 42953.9184\n",
      "Epoch 221/1200\n",
      "1137/1137 [==============================] - 1s 531us/step - loss: 27063.1670 - val_loss: 41150.4557\n",
      "Epoch 222/1200\n",
      "1137/1137 [==============================] - 1s 538us/step - loss: 27398.6386 - val_loss: 42261.3053\n",
      "Epoch 223/1200\n",
      "1137/1137 [==============================] - 1s 542us/step - loss: 27563.9511 - val_loss: 41650.7883\n",
      "Epoch 224/1200\n",
      "1137/1137 [==============================] - 1s 536us/step - loss: 26924.4656 - val_loss: 41328.2457\n",
      "Epoch 225/1200\n",
      "1137/1137 [==============================] - 1s 538us/step - loss: 27389.7289 - val_loss: 41379.0156\n",
      "Epoch 226/1200\n",
      "1137/1137 [==============================] - 1s 540us/step - loss: 27956.0963 - val_loss: 42292.8762\n",
      "Epoch 227/1200\n",
      "1137/1137 [==============================] - 1s 581us/step - loss: 27113.8099 - val_loss: 41062.9399\n",
      "Epoch 228/1200\n",
      "1137/1137 [==============================] - 1s 584us/step - loss: 26984.7385 - val_loss: 41150.0921\n",
      "Epoch 229/1200\n",
      "1137/1137 [==============================] - 1s 543us/step - loss: 26674.1869 - val_loss: 40695.9643\n",
      "Epoch 230/1200\n",
      "1137/1137 [==============================] - 1s 532us/step - loss: 26622.0739 - val_loss: 40937.7705\n",
      "Epoch 231/1200\n",
      "1137/1137 [==============================] - 1s 579us/step - loss: 26968.1163 - val_loss: 41028.5631\n",
      "Epoch 232/1200\n",
      "1137/1137 [==============================] - 1s 541us/step - loss: 26812.5645 - val_loss: 41998.5875\n",
      "Epoch 233/1200\n",
      "1137/1137 [==============================] - 1s 573us/step - loss: 26645.2590 - val_loss: 40539.0464\n",
      "Epoch 234/1200\n",
      "1137/1137 [==============================] - 1s 553us/step - loss: 26628.2146 - val_loss: 40291.6257\n",
      "Epoch 235/1200\n",
      "1137/1137 [==============================] - 1s 580us/step - loss: 26191.0080 - val_loss: 42531.5931\n",
      "Epoch 236/1200\n",
      "1137/1137 [==============================] - 1s 581us/step - loss: 27004.9430 - val_loss: 40672.1830\n",
      "Epoch 237/1200\n",
      "1137/1137 [==============================] - 1s 532us/step - loss: 26763.7422 - val_loss: 40691.2096\n",
      "Epoch 238/1200\n",
      "1137/1137 [==============================] - 1s 522us/step - loss: 26803.8136 - val_loss: 41390.6710\n",
      "Epoch 239/1200\n",
      "1137/1137 [==============================] - 1s 533us/step - loss: 27284.3152 - val_loss: 40483.8955\n",
      "Epoch 240/1200\n",
      "1137/1137 [==============================] - 1s 576us/step - loss: 26704.5147 - val_loss: 41164.9867\n",
      "Epoch 241/1200\n",
      "1137/1137 [==============================] - 1s 532us/step - loss: 26405.9622 - val_loss: 40718.9215\n",
      "Epoch 242/1200\n",
      "1137/1137 [==============================] - 1s 576us/step - loss: 26546.0946 - val_loss: 40324.6601\n",
      "Epoch 243/1200\n",
      "1137/1137 [==============================] - 1s 531us/step - loss: 26480.6633 - val_loss: 41303.6906\n",
      "Epoch 244/1200\n",
      "1137/1137 [==============================] - 1s 576us/step - loss: 26452.0444 - val_loss: 40006.5995\n",
      "Epoch 245/1200\n",
      "1137/1137 [==============================] - 1s 591us/step - loss: 26330.3778 - val_loss: 40909.6567\n",
      "Epoch 246/1200\n",
      "1137/1137 [==============================] - 1s 588us/step - loss: 26695.0160 - val_loss: 40117.5028\n",
      "Epoch 247/1200\n",
      "1137/1137 [==============================] - 1s 591us/step - loss: 26408.1555 - val_loss: 40259.9985\n",
      "Epoch 248/1200\n",
      "1137/1137 [==============================] - 1s 584us/step - loss: 26483.4046 - val_loss: 39882.1684\n",
      "Epoch 249/1200\n",
      "1137/1137 [==============================] - 1s 568us/step - loss: 25703.6014 - val_loss: 41442.0532\n",
      "Epoch 250/1200\n",
      "1137/1137 [==============================] - 1s 557us/step - loss: 26193.2299 - val_loss: 39821.0170\n",
      "Epoch 251/1200\n",
      "1137/1137 [==============================] - 1s 594us/step - loss: 26281.7091 - val_loss: 42278.1338\n",
      "Epoch 252/1200\n",
      "1137/1137 [==============================] - 1s 531us/step - loss: 26139.5973 - val_loss: 42574.0565\n",
      "Epoch 253/1200\n",
      "1137/1137 [==============================] - 1s 532us/step - loss: 26467.8974 - val_loss: 40630.9181\n",
      "Epoch 254/1200\n",
      "1137/1137 [==============================] - 1s 534us/step - loss: 26022.8191 - val_loss: 40936.4824\n",
      "Epoch 255/1200\n",
      "1137/1137 [==============================] - 1s 576us/step - loss: 25790.8674 - val_loss: 39747.8088\n",
      "Epoch 256/1200\n",
      "1137/1137 [==============================] - 1s 549us/step - loss: 25740.7796 - val_loss: 40210.8766\n",
      "Epoch 257/1200\n",
      "1137/1137 [==============================] - 1s 528us/step - loss: 26131.0913 - val_loss: 39179.9135\n",
      "Epoch 258/1200\n",
      "1137/1137 [==============================] - 1s 560us/step - loss: 25954.6806 - val_loss: 39280.1055\n",
      "Epoch 259/1200\n",
      "1137/1137 [==============================] - 1s 592us/step - loss: 26081.8851 - val_loss: 39915.4095\n",
      "Epoch 260/1200\n",
      "1137/1137 [==============================] - 1s 527us/step - loss: 26407.4189 - val_loss: 39976.0151\n",
      "Epoch 261/1200\n",
      "1137/1137 [==============================] - 1s 538us/step - loss: 25777.8409 - val_loss: 40981.5727\n",
      "Epoch 262/1200\n",
      "1137/1137 [==============================] - 1s 537us/step - loss: 26413.8914 - val_loss: 42145.7907\n",
      "Epoch 263/1200\n",
      "1137/1137 [==============================] - 1s 520us/step - loss: 25469.4930 - val_loss: 39862.2153\n",
      "Epoch 264/1200\n",
      "1137/1137 [==============================] - 1s 526us/step - loss: 25847.5172 - val_loss: 39887.2450\n",
      "Epoch 265/1200\n",
      "1137/1137 [==============================] - 1s 522us/step - loss: 26010.9197 - val_loss: 39138.3972\n",
      "Epoch 266/1200\n",
      "1137/1137 [==============================] - 1s 567us/step - loss: 25288.9026 - val_loss: 39169.8742\n",
      "Epoch 267/1200\n",
      "1137/1137 [==============================] - 1s 543us/step - loss: 24998.0084 - val_loss: 38911.7147\n",
      "Epoch 268/1200\n",
      "1137/1137 [==============================] - 1s 544us/step - loss: 25321.2880 - val_loss: 41839.3078\n",
      "Epoch 269/1200\n",
      "1137/1137 [==============================] - 1s 546us/step - loss: 26018.0264 - val_loss: 40430.6051\n",
      "Epoch 270/1200\n",
      "1137/1137 [==============================] - 1s 533us/step - loss: 25603.2359 - val_loss: 40448.3186\n",
      "Epoch 271/1200\n",
      "1137/1137 [==============================] - 1s 573us/step - loss: 25693.9751 - val_loss: 39453.8795\n",
      "Epoch 272/1200\n",
      "1137/1137 [==============================] - 1s 549us/step - loss: 26326.6567 - val_loss: 39110.8423\n",
      "Epoch 273/1200\n",
      "1137/1137 [==============================] - 1s 595us/step - loss: 25571.7485 - val_loss: 38523.2882\n",
      "Epoch 274/1200\n",
      "1137/1137 [==============================] - 1s 546us/step - loss: 25412.2570 - val_loss: 38603.1847\n",
      "Epoch 275/1200\n",
      "1137/1137 [==============================] - 1s 575us/step - loss: 25022.1043 - val_loss: 38819.1495\n",
      "Epoch 276/1200\n",
      "1137/1137 [==============================] - 1s 557us/step - loss: 25394.8433 - val_loss: 38532.2556\n",
      "Epoch 277/1200\n",
      "1137/1137 [==============================] - 1s 579us/step - loss: 25572.4732 - val_loss: 38971.1537\n",
      "Epoch 278/1200\n",
      "1137/1137 [==============================] - 1s 583us/step - loss: 25268.6716 - val_loss: 39002.5559\n",
      "Epoch 279/1200\n",
      "1137/1137 [==============================] - 1s 581us/step - loss: 25314.3592 - val_loss: 38265.1970\n",
      "Epoch 280/1200\n",
      "1137/1137 [==============================] - 1s 554us/step - loss: 24800.4330 - val_loss: 40875.5703\n",
      "Epoch 281/1200\n",
      "1137/1137 [==============================] - 1s 541us/step - loss: 25626.3168 - val_loss: 39015.1555\n",
      "Epoch 282/1200\n",
      "1137/1137 [==============================] - 1s 579us/step - loss: 25234.1806 - val_loss: 39315.6622\n",
      "Epoch 283/1200\n",
      "1137/1137 [==============================] - 1s 553us/step - loss: 25144.4794 - val_loss: 38742.2486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284/1200\n",
      "1137/1137 [==============================] - 1s 594us/step - loss: 24433.5906 - val_loss: 38494.2527\n",
      "Epoch 285/1200\n",
      "1137/1137 [==============================] - 1s 533us/step - loss: 24829.9282 - val_loss: 38556.2682\n",
      "Epoch 286/1200\n",
      "1137/1137 [==============================] - 1s 523us/step - loss: 24496.7176 - val_loss: 38748.5084\n",
      "Epoch 287/1200\n",
      "1137/1137 [==============================] - 1s 547us/step - loss: 24685.1798 - val_loss: 38231.4379\n",
      "Epoch 288/1200\n",
      "1137/1137 [==============================] - 1s 589us/step - loss: 24302.6560 - val_loss: 38103.1030\n",
      "Epoch 289/1200\n",
      "1137/1137 [==============================] - 1s 527us/step - loss: 24498.6485 - val_loss: 42724.7778\n",
      "Epoch 290/1200\n",
      "1137/1137 [==============================] - 1s 540us/step - loss: 24894.2115 - val_loss: 39680.3188\n",
      "Epoch 291/1200\n",
      "1137/1137 [==============================] - 1s 530us/step - loss: 24842.7316 - val_loss: 38085.2196\n",
      "Epoch 292/1200\n",
      "1137/1137 [==============================] - 1s 564us/step - loss: 25075.4658 - val_loss: 38429.2456\n",
      "Epoch 293/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 24446.1764 - val_loss: 38799.7363\n",
      "Epoch 294/1200\n",
      "1137/1137 [==============================] - 1s 532us/step - loss: 24687.5113 - val_loss: 38072.5635\n",
      "Epoch 295/1200\n",
      "1137/1137 [==============================] - 1s 548us/step - loss: 25167.9242 - val_loss: 39166.3209\n",
      "Epoch 296/1200\n",
      "1137/1137 [==============================] - 1s 528us/step - loss: 24929.2999 - val_loss: 37882.3342\n",
      "Epoch 297/1200\n",
      "1137/1137 [==============================] - 1s 587us/step - loss: 24467.3052 - val_loss: 37518.1839\n",
      "Epoch 298/1200\n",
      "1137/1137 [==============================] - 1s 546us/step - loss: 24729.4086 - val_loss: 37972.1352\n",
      "Epoch 299/1200\n",
      "1137/1137 [==============================] - 1s 549us/step - loss: 24812.3104 - val_loss: 38401.0688\n",
      "Epoch 300/1200\n",
      "1137/1137 [==============================] - 1s 540us/step - loss: 24531.1855 - val_loss: 38924.0728\n",
      "Epoch 301/1200\n",
      "1137/1137 [==============================] - 1s 577us/step - loss: 24289.6654 - val_loss: 38491.9687\n",
      "Epoch 302/1200\n",
      "1137/1137 [==============================] - 1s 550us/step - loss: 24686.7640 - val_loss: 37943.6789\n",
      "Epoch 303/1200\n",
      "1137/1137 [==============================] - 1s 537us/step - loss: 24207.8594 - val_loss: 37613.7057\n",
      "Epoch 304/1200\n",
      "1137/1137 [==============================] - 1s 545us/step - loss: 24416.9042 - val_loss: 37229.8628\n",
      "Epoch 305/1200\n",
      "1137/1137 [==============================] - 1s 563us/step - loss: 24312.6328 - val_loss: 37100.8261\n",
      "Epoch 306/1200\n",
      "1137/1137 [==============================] - 1s 589us/step - loss: 25221.8701 - val_loss: 37392.9870\n",
      "Epoch 307/1200\n",
      "1137/1137 [==============================] - 1s 582us/step - loss: 24360.8905 - val_loss: 38872.1145\n",
      "Epoch 308/1200\n",
      "1137/1137 [==============================] - 1s 543us/step - loss: 23978.8674 - val_loss: 36761.3188\n",
      "Epoch 309/1200\n",
      "1137/1137 [==============================] - 1s 528us/step - loss: 24655.8031 - val_loss: 39717.6859\n",
      "Epoch 310/1200\n",
      "1137/1137 [==============================] - 1s 558us/step - loss: 25388.7854 - val_loss: 39524.5961\n",
      "Epoch 311/1200\n",
      "1137/1137 [==============================] - 1s 534us/step - loss: 24392.8886 - val_loss: 37381.7298\n",
      "Epoch 312/1200\n",
      "1137/1137 [==============================] - 1s 528us/step - loss: 24228.7714 - val_loss: 36506.4744\n",
      "Epoch 313/1200\n",
      "1137/1137 [==============================] - 1s 560us/step - loss: 24184.6817 - val_loss: 38667.2747\n",
      "Epoch 314/1200\n",
      "1137/1137 [==============================] - 1s 569us/step - loss: 23733.5358 - val_loss: 37895.8398\n",
      "Epoch 315/1200\n",
      "1137/1137 [==============================] - 1s 573us/step - loss: 24368.6156 - val_loss: 38561.3825\n",
      "Epoch 316/1200\n",
      "1137/1137 [==============================] - 1s 565us/step - loss: 24250.0968 - val_loss: 37418.8992\n",
      "Epoch 317/1200\n",
      "1137/1137 [==============================] - 1s 525us/step - loss: 24459.0008 - val_loss: 39335.8242\n",
      "Epoch 318/1200\n",
      "1137/1137 [==============================] - 1s 540us/step - loss: 24065.2470 - val_loss: 38227.1453\n",
      "Epoch 319/1200\n",
      "1137/1137 [==============================] - 1s 530us/step - loss: 23944.4743 - val_loss: 36543.8389\n",
      "Epoch 320/1200\n",
      "1137/1137 [==============================] - 1s 533us/step - loss: 24065.5474 - val_loss: 37144.8491\n",
      "Epoch 321/1200\n",
      "1137/1137 [==============================] - 1s 545us/step - loss: 23949.8617 - val_loss: 39721.9879\n",
      "Epoch 322/1200\n",
      "1137/1137 [==============================] - 1s 548us/step - loss: 23764.6757 - val_loss: 37951.2559\n",
      "Epoch 323/1200\n",
      "1137/1137 [==============================] - 1s 519us/step - loss: 24019.6361 - val_loss: 37308.1247\n",
      "Epoch 324/1200\n",
      "1137/1137 [==============================] - 1s 569us/step - loss: 24200.3872 - val_loss: 36493.3129\n",
      "Epoch 325/1200\n",
      "1137/1137 [==============================] - 1s 567us/step - loss: 23521.9364 - val_loss: 38030.1941\n",
      "Epoch 326/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 23760.0065 - val_loss: 38223.7168\n",
      "Epoch 327/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 23648.1831 - val_loss: 40198.1920\n",
      "Epoch 328/1200\n",
      "1137/1137 [==============================] - 1s 602us/step - loss: 24210.7406 - val_loss: 37641.5190\n",
      "Epoch 329/1200\n",
      "1137/1137 [==============================] - 1s 594us/step - loss: 23957.8315 - val_loss: 37018.8917\n",
      "Epoch 330/1200\n",
      "1137/1137 [==============================] - 1s 608us/step - loss: 23701.1820 - val_loss: 37238.4509\n",
      "Epoch 331/1200\n",
      "1137/1137 [==============================] - 1s 609us/step - loss: 24327.6464 - val_loss: 36659.7740\n",
      "Epoch 332/1200\n",
      "1137/1137 [==============================] - 1s 567us/step - loss: 24345.1311 - val_loss: 41053.1739\n",
      "Epoch 333/1200\n",
      "1137/1137 [==============================] - 1s 567us/step - loss: 23837.1982 - val_loss: 36266.3749\n",
      "Epoch 334/1200\n",
      "1137/1137 [==============================] - 1s 585us/step - loss: 23442.6721 - val_loss: 36675.3667\n",
      "Epoch 335/1200\n",
      "1137/1137 [==============================] - 1s 546us/step - loss: 23607.3414 - val_loss: 37192.0929\n",
      "Epoch 336/1200\n",
      "1137/1137 [==============================] - 1s 545us/step - loss: 23924.5487 - val_loss: 37469.5609\n",
      "Epoch 337/1200\n",
      "1137/1137 [==============================] - 1s 600us/step - loss: 23739.0822 - val_loss: 38640.5891\n",
      "Epoch 338/1200\n",
      "1137/1137 [==============================] - 1s 585us/step - loss: 23559.2175 - val_loss: 36768.7684\n",
      "Epoch 339/1200\n",
      "1137/1137 [==============================] - 1s 575us/step - loss: 23700.6485 - val_loss: 36177.4288\n",
      "Epoch 340/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 23143.2885 - val_loss: 36233.2541\n",
      "Epoch 341/1200\n",
      "1137/1137 [==============================] - 1s 588us/step - loss: 23964.4184 - val_loss: 36790.8906\n",
      "Epoch 342/1200\n",
      "1137/1137 [==============================] - 1s 610us/step - loss: 23722.0895 - val_loss: 35836.8230\n",
      "Epoch 343/1200\n",
      "1137/1137 [==============================] - 1s 564us/step - loss: 23344.1845 - val_loss: 36347.6238\n",
      "Epoch 344/1200\n",
      "1137/1137 [==============================] - 1s 548us/step - loss: 23979.6444 - val_loss: 36890.2783\n",
      "Epoch 345/1200\n",
      "1137/1137 [==============================] - 1s 551us/step - loss: 23874.0510 - val_loss: 36260.9461\n",
      "Epoch 346/1200\n",
      "1137/1137 [==============================] - 1s 552us/step - loss: 23280.9071 - val_loss: 36645.1773\n",
      "Epoch 347/1200\n",
      "1137/1137 [==============================] - 1s 547us/step - loss: 23212.3849 - val_loss: 35713.2190\n",
      "Epoch 348/1200\n",
      "1137/1137 [==============================] - 1s 602us/step - loss: 23179.9034 - val_loss: 36124.8629\n",
      "Epoch 349/1200\n",
      "1137/1137 [==============================] - 1s 552us/step - loss: 23507.6685 - val_loss: 36365.6523\n",
      "Epoch 350/1200\n",
      "1137/1137 [==============================] - 1s 578us/step - loss: 23403.5563 - val_loss: 38489.0909\n",
      "Epoch 351/1200\n",
      "1137/1137 [==============================] - 1s 562us/step - loss: 23392.1148 - val_loss: 35434.6015\n",
      "Epoch 352/1200\n",
      "1137/1137 [==============================] - 1s 553us/step - loss: 23137.6016 - val_loss: 36201.9598\n",
      "Epoch 353/1200\n",
      "1137/1137 [==============================] - 1s 543us/step - loss: 23503.3058 - val_loss: 36659.9131\n",
      "Epoch 354/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 1s 599us/step - loss: 23168.1422 - val_loss: 37496.0304\n",
      "Epoch 355/1200\n",
      "1137/1137 [==============================] - 1s 542us/step - loss: 23492.5115 - val_loss: 35788.4031\n",
      "Epoch 356/1200\n",
      "1137/1137 [==============================] - 1s 587us/step - loss: 23920.9131 - val_loss: 35835.4877\n",
      "Epoch 357/1200\n",
      "1137/1137 [==============================] - 1s 603us/step - loss: 23631.1007 - val_loss: 36046.0378\n",
      "Epoch 358/1200\n",
      "1137/1137 [==============================] - 1s 568us/step - loss: 22866.1096 - val_loss: 35582.4382\n",
      "Epoch 359/1200\n",
      "1137/1137 [==============================] - 1s 541us/step - loss: 23359.9418 - val_loss: 35485.2344\n",
      "Epoch 360/1200\n",
      "1137/1137 [==============================] - 1s 597us/step - loss: 22850.7160 - val_loss: 37271.1640\n",
      "Epoch 361/1200\n",
      "1137/1137 [==============================] - 1s 584us/step - loss: 23054.6708 - val_loss: 35569.3010\n",
      "Epoch 362/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 23677.0716 - val_loss: 35503.3808\n",
      "Epoch 363/1200\n",
      "1137/1137 [==============================] - 1s 566us/step - loss: 22876.5678 - val_loss: 39895.7358\n",
      "Epoch 364/1200\n",
      "1137/1137 [==============================] - 1s 543us/step - loss: 23205.7514 - val_loss: 36092.6791\n",
      "Epoch 365/1200\n",
      "1137/1137 [==============================] - 1s 583us/step - loss: 23230.5140 - val_loss: 35343.4681\n",
      "Epoch 366/1200\n",
      "1137/1137 [==============================] - 1s 546us/step - loss: 23232.7711 - val_loss: 35426.3989\n",
      "Epoch 367/1200\n",
      "1137/1137 [==============================] - 1s 559us/step - loss: 23239.6690 - val_loss: 35803.5779\n",
      "Epoch 368/1200\n",
      "1137/1137 [==============================] - 1s 582us/step - loss: 23126.9286 - val_loss: 36408.8831\n",
      "Epoch 369/1200\n",
      "1137/1137 [==============================] - 1s 544us/step - loss: 23246.2594 - val_loss: 36597.7026\n",
      "Epoch 370/1200\n",
      "1137/1137 [==============================] - 1s 556us/step - loss: 23168.4147 - val_loss: 35819.3801\n",
      "Epoch 371/1200\n",
      "1137/1137 [==============================] - 1s 530us/step - loss: 23173.9041 - val_loss: 35217.1187\n",
      "Epoch 372/1200\n",
      "1137/1137 [==============================] - 1s 532us/step - loss: 22975.8157 - val_loss: 35133.4685\n",
      "Epoch 373/1200\n",
      "1137/1137 [==============================] - 1s 609us/step - loss: 23090.2767 - val_loss: 35926.7636\n",
      "Epoch 374/1200\n",
      "1137/1137 [==============================] - 1s 556us/step - loss: 22508.2260 - val_loss: 35224.1148\n",
      "Epoch 375/1200\n",
      "1137/1137 [==============================] - 1s 545us/step - loss: 22854.9205 - val_loss: 36061.7058\n",
      "Epoch 376/1200\n",
      "1137/1137 [==============================] - 1s 584us/step - loss: 23893.2360 - val_loss: 37857.5776\n",
      "Epoch 377/1200\n",
      "1137/1137 [==============================] - 1s 574us/step - loss: 23066.5879 - val_loss: 35703.6929\n",
      "Epoch 378/1200\n",
      "1137/1137 [==============================] - 1s 533us/step - loss: 22850.6800 - val_loss: 36208.4211\n",
      "Epoch 379/1200\n",
      "1137/1137 [==============================] - 1s 549us/step - loss: 22772.3990 - val_loss: 37903.2151\n",
      "Epoch 380/1200\n",
      "1137/1137 [==============================] - 1s 591us/step - loss: 22800.6406 - val_loss: 35142.8570\n",
      "Epoch 381/1200\n",
      "1137/1137 [==============================] - 1s 568us/step - loss: 22760.0680 - val_loss: 35011.7443\n",
      "Epoch 382/1200\n",
      "1137/1137 [==============================] - 1s 582us/step - loss: 22986.6666 - val_loss: 35208.3713\n",
      "Epoch 383/1200\n",
      "1137/1137 [==============================] - 1s 568us/step - loss: 22662.6381 - val_loss: 35097.1054\n",
      "Epoch 384/1200\n",
      "1137/1137 [==============================] - 1s 585us/step - loss: 22379.4456 - val_loss: 36299.7287\n",
      "Epoch 385/1200\n",
      "1137/1137 [==============================] - 1s 603us/step - loss: 22714.8838 - val_loss: 36836.6527\n",
      "Epoch 386/1200\n",
      "1137/1137 [==============================] - 1s 545us/step - loss: 22431.3049 - val_loss: 36361.4571\n",
      "Epoch 387/1200\n",
      "1137/1137 [==============================] - 1s 581us/step - loss: 22271.4320 - val_loss: 35586.9772\n",
      "Epoch 388/1200\n",
      "1137/1137 [==============================] - 1s 568us/step - loss: 22398.4474 - val_loss: 36036.1307\n",
      "Epoch 389/1200\n",
      "1137/1137 [==============================] - 1s 568us/step - loss: 22705.1434 - val_loss: 34818.2988\n",
      "Epoch 390/1200\n",
      "1137/1137 [==============================] - 1s 533us/step - loss: 22948.3135 - val_loss: 35074.3324\n",
      "Epoch 391/1200\n",
      "1137/1137 [==============================] - 1s 536us/step - loss: 22925.9018 - val_loss: 34814.4782\n",
      "Epoch 392/1200\n",
      "1137/1137 [==============================] - 1s 536us/step - loss: 22264.5656 - val_loss: 34873.1071\n",
      "Epoch 393/1200\n",
      "1137/1137 [==============================] - 1s 528us/step - loss: 22388.0485 - val_loss: 34616.7636\n",
      "Epoch 394/1200\n",
      "1137/1137 [==============================] - 1s 542us/step - loss: 22051.1279 - val_loss: 35345.2329\n",
      "Epoch 395/1200\n",
      "1137/1137 [==============================] - 1s 537us/step - loss: 22400.5102 - val_loss: 36380.0150\n",
      "Epoch 396/1200\n",
      "1137/1137 [==============================] - 1s 570us/step - loss: 22273.3598 - val_loss: 35531.1365\n",
      "Epoch 397/1200\n",
      "1137/1137 [==============================] - 1s 599us/step - loss: 22248.0289 - val_loss: 35555.0866\n",
      "Epoch 398/1200\n",
      "1137/1137 [==============================] - 1s 549us/step - loss: 22585.8011 - val_loss: 35180.9269\n",
      "Epoch 399/1200\n",
      "1137/1137 [==============================] - 1s 535us/step - loss: 22444.2484 - val_loss: 36751.1444\n",
      "Epoch 400/1200\n",
      "1137/1137 [==============================] - 1s 525us/step - loss: 22385.7014 - val_loss: 35207.0334\n",
      "Epoch 401/1200\n",
      "1137/1137 [==============================] - 1s 560us/step - loss: 22939.4583 - val_loss: 34524.5668\n",
      "Epoch 402/1200\n",
      "1137/1137 [==============================] - 1s 589us/step - loss: 21884.7742 - val_loss: 34827.1762\n",
      "Epoch 403/1200\n",
      "1137/1137 [==============================] - 1s 615us/step - loss: 22022.6099 - val_loss: 34740.7617\n",
      "Epoch 404/1200\n",
      "1137/1137 [==============================] - 1s 589us/step - loss: 22533.3473 - val_loss: 35409.7420\n",
      "Epoch 405/1200\n",
      "1137/1137 [==============================] - 1s 580us/step - loss: 22295.8170 - val_loss: 34716.0539\n",
      "Epoch 406/1200\n",
      "1137/1137 [==============================] - 1s 533us/step - loss: 22908.0607 - val_loss: 34237.0700\n",
      "Epoch 407/1200\n",
      "1137/1137 [==============================] - 1s 563us/step - loss: 21996.0604 - val_loss: 36249.5149\n",
      "Epoch 408/1200\n",
      "1137/1137 [==============================] - 1s 576us/step - loss: 22403.1165 - val_loss: 34264.8267\n",
      "Epoch 409/1200\n",
      "1137/1137 [==============================] - 1s 538us/step - loss: 22686.0231 - val_loss: 35402.2280\n",
      "Epoch 410/1200\n",
      "1137/1137 [==============================] - 1s 538us/step - loss: 22616.3397 - val_loss: 33813.2125\n",
      "Epoch 411/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 22519.9536 - val_loss: 35316.2196\n",
      "Epoch 412/1200\n",
      "1137/1137 [==============================] - 1s 546us/step - loss: 22616.1644 - val_loss: 34497.3204\n",
      "Epoch 413/1200\n",
      "1137/1137 [==============================] - 1s 564us/step - loss: 22173.4007 - val_loss: 38194.5345\n",
      "Epoch 414/1200\n",
      "1137/1137 [==============================] - 1s 591us/step - loss: 22397.8784 - val_loss: 34362.1866\n",
      "Epoch 415/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 22236.7624 - val_loss: 34233.4235\n",
      "Epoch 416/1200\n",
      "1137/1137 [==============================] - 1s 527us/step - loss: 21965.8036 - val_loss: 34075.9589\n",
      "Epoch 417/1200\n",
      "1137/1137 [==============================] - 1s 575us/step - loss: 22163.9068 - val_loss: 35737.7480\n",
      "Epoch 418/1200\n",
      "1137/1137 [==============================] - 1s 548us/step - loss: 21973.7606 - val_loss: 34244.8985\n",
      "Epoch 419/1200\n",
      "1137/1137 [==============================] - 1s 530us/step - loss: 22013.2182 - val_loss: 34370.1560\n",
      "Epoch 420/1200\n",
      "1137/1137 [==============================] - 1s 536us/step - loss: 22026.6247 - val_loss: 34907.8307\n",
      "Epoch 421/1200\n",
      "1137/1137 [==============================] - 1s 566us/step - loss: 22327.1732 - val_loss: 34375.5136\n",
      "Epoch 422/1200\n",
      "1137/1137 [==============================] - 1s 543us/step - loss: 22245.1079 - val_loss: 35091.1716\n",
      "Epoch 423/1200\n",
      "1137/1137 [==============================] - 1s 529us/step - loss: 22091.5347 - val_loss: 34485.6448\n",
      "Epoch 424/1200\n",
      "1137/1137 [==============================] - 1s 588us/step - loss: 21357.0376 - val_loss: 34798.0217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 425/1200\n",
      "1137/1137 [==============================] - 1s 553us/step - loss: 22041.8451 - val_loss: 36023.1076\n",
      "Epoch 426/1200\n",
      "1137/1137 [==============================] - 1s 548us/step - loss: 22196.7205 - val_loss: 36151.0050\n",
      "Epoch 427/1200\n",
      "1137/1137 [==============================] - 1s 527us/step - loss: 21970.6162 - val_loss: 35004.4105\n",
      "Epoch 428/1200\n",
      "1137/1137 [==============================] - 1s 552us/step - loss: 22099.7986 - val_loss: 36817.6402\n",
      "Epoch 429/1200\n",
      "1137/1137 [==============================] - 1s 551us/step - loss: 21701.3687 - val_loss: 36961.2111\n",
      "Epoch 430/1200\n",
      "1137/1137 [==============================] - 1s 538us/step - loss: 22171.2050 - val_loss: 35592.6549\n",
      "Epoch 431/1200\n",
      "1137/1137 [==============================] - 1s 586us/step - loss: 22094.2099 - val_loss: 35483.6453\n",
      "Epoch 432/1200\n",
      "1137/1137 [==============================] - 1s 554us/step - loss: 21967.6529 - val_loss: 33692.6554\n",
      "Epoch 433/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 20972.7238 - val_loss: 34420.6259\n",
      "Epoch 434/1200\n",
      "1137/1137 [==============================] - 1s 531us/step - loss: 21444.1244 - val_loss: 35017.1719\n",
      "Epoch 435/1200\n",
      "1137/1137 [==============================] - 1s 541us/step - loss: 21747.8473 - val_loss: 34337.8481\n",
      "Epoch 436/1200\n",
      "1137/1137 [==============================] - 1s 537us/step - loss: 22291.0932 - val_loss: 33497.7390\n",
      "Epoch 437/1200\n",
      "1137/1137 [==============================] - 1s 580us/step - loss: 21518.4735 - val_loss: 34085.2638\n",
      "Epoch 438/1200\n",
      "1137/1137 [==============================] - 1s 566us/step - loss: 21718.3218 - val_loss: 33302.1637\n",
      "Epoch 439/1200\n",
      "1137/1137 [==============================] - 1s 523us/step - loss: 21884.9711 - val_loss: 33283.4098\n",
      "Epoch 440/1200\n",
      "1137/1137 [==============================] - 1s 533us/step - loss: 21343.9539 - val_loss: 33572.7011\n",
      "Epoch 441/1200\n",
      "1137/1137 [==============================] - 1s 575us/step - loss: 21358.9278 - val_loss: 34286.8139\n",
      "Epoch 442/1200\n",
      "1137/1137 [==============================] - 1s 554us/step - loss: 20743.4567 - val_loss: 33946.0836\n",
      "Epoch 443/1200\n",
      "1137/1137 [==============================] - 1s 540us/step - loss: 21271.1360 - val_loss: 35632.2228\n",
      "Epoch 444/1200\n",
      "1137/1137 [==============================] - 1s 551us/step - loss: 22039.5122 - val_loss: 33573.6725\n",
      "Epoch 445/1200\n",
      "1137/1137 [==============================] - 1s 568us/step - loss: 20908.0544 - val_loss: 34790.4994\n",
      "Epoch 446/1200\n",
      "1137/1137 [==============================] - 1s 592us/step - loss: 21877.4918 - val_loss: 34643.7000\n",
      "Epoch 447/1200\n",
      "1137/1137 [==============================] - 1s 581us/step - loss: 21488.8751 - val_loss: 34033.8282\n",
      "Epoch 448/1200\n",
      "1137/1137 [==============================] - 1s 549us/step - loss: 21902.0504 - val_loss: 33025.4066\n",
      "Epoch 449/1200\n",
      "1137/1137 [==============================] - 1s 574us/step - loss: 21387.5300 - val_loss: 34278.3373\n",
      "Epoch 450/1200\n",
      "1137/1137 [==============================] - 1s 565us/step - loss: 21445.7532 - val_loss: 32966.8525\n",
      "Epoch 451/1200\n",
      "1137/1137 [==============================] - 1s 537us/step - loss: 21687.2501 - val_loss: 34414.6365\n",
      "Epoch 452/1200\n",
      "1137/1137 [==============================] - 1s 561us/step - loss: 21205.4593 - val_loss: 33974.6096\n",
      "Epoch 453/1200\n",
      "1137/1137 [==============================] - 1s 530us/step - loss: 21133.7900 - val_loss: 33051.1556\n",
      "Epoch 454/1200\n",
      "1137/1137 [==============================] - 1s 548us/step - loss: 21358.2513 - val_loss: 33851.7342\n",
      "Epoch 455/1200\n",
      "1137/1137 [==============================] - 1s 577us/step - loss: 21697.8098 - val_loss: 33317.6117\n",
      "Epoch 456/1200\n",
      "1137/1137 [==============================] - 1s 598us/step - loss: 21043.7478 - val_loss: 34290.5798\n",
      "Epoch 457/1200\n",
      "1137/1137 [==============================] - 1s 592us/step - loss: 20922.5098 - val_loss: 34075.0327\n",
      "Epoch 458/1200\n",
      "1137/1137 [==============================] - 1s 558us/step - loss: 21339.6416 - val_loss: 34311.1526\n",
      "Epoch 459/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 21220.2187 - val_loss: 33966.5404\n",
      "Epoch 460/1200\n",
      "1137/1137 [==============================] - 1s 544us/step - loss: 21022.4889 - val_loss: 36695.6507\n",
      "Epoch 461/1200\n",
      "1137/1137 [==============================] - 1s 598us/step - loss: 20999.3148 - val_loss: 33300.4921\n",
      "Epoch 462/1200\n",
      "1137/1137 [==============================] - 1s 580us/step - loss: 21363.2794 - val_loss: 37721.3626\n",
      "Epoch 463/1200\n",
      "1137/1137 [==============================] - 1s 572us/step - loss: 21327.1411 - val_loss: 35282.4791\n",
      "Epoch 464/1200\n",
      "1137/1137 [==============================] - 1s 585us/step - loss: 21059.1670 - val_loss: 32582.6282\n",
      "Epoch 465/1200\n",
      "1137/1137 [==============================] - 1s 522us/step - loss: 21436.0389 - val_loss: 37528.0856\n",
      "Epoch 466/1200\n",
      "1137/1137 [==============================] - 1s 584us/step - loss: 21435.0358 - val_loss: 32721.3507\n",
      "Epoch 467/1200\n",
      "1137/1137 [==============================] - 1s 596us/step - loss: 20522.5790 - val_loss: 33200.8560\n",
      "Epoch 468/1200\n",
      "1137/1137 [==============================] - 1s 564us/step - loss: 21487.0593 - val_loss: 33482.4945\n",
      "Epoch 469/1200\n",
      "1137/1137 [==============================] - 1s 578us/step - loss: 20672.0027 - val_loss: 33202.8509\n",
      "Epoch 470/1200\n",
      "1137/1137 [==============================] - 1s 525us/step - loss: 20646.8094 - val_loss: 33686.2708\n",
      "Epoch 471/1200\n",
      "1137/1137 [==============================] - 1s 590us/step - loss: 21170.9637 - val_loss: 34797.8065\n",
      "Epoch 472/1200\n",
      "1137/1137 [==============================] - 1s 585us/step - loss: 21007.5322 - val_loss: 33283.1402\n",
      "Epoch 473/1200\n",
      "1137/1137 [==============================] - 1s 534us/step - loss: 20822.9330 - val_loss: 34360.6505\n",
      "Epoch 474/1200\n",
      "1137/1137 [==============================] - 1s 553us/step - loss: 21190.5329 - val_loss: 33064.9271\n",
      "Epoch 475/1200\n",
      "1137/1137 [==============================] - 1s 610us/step - loss: 21233.4497 - val_loss: 33193.8078\n",
      "Epoch 476/1200\n",
      "1137/1137 [==============================] - 1s 590us/step - loss: 20885.2364 - val_loss: 32973.0045\n",
      "Epoch 477/1200\n",
      "1137/1137 [==============================] - 1s 596us/step - loss: 20485.4049 - val_loss: 33083.7504\n",
      "Epoch 478/1200\n",
      "1137/1137 [==============================] - 1s 542us/step - loss: 20850.3594 - val_loss: 32774.2923\n",
      "Epoch 479/1200\n",
      "1137/1137 [==============================] - 1s 571us/step - loss: 20938.7032 - val_loss: 32481.2932\n",
      "Epoch 480/1200\n",
      "1137/1137 [==============================] - 1s 574us/step - loss: 20617.0762 - val_loss: 32355.5124\n",
      "Epoch 481/1200\n",
      "1137/1137 [==============================] - 1s 585us/step - loss: 20348.5531 - val_loss: 34077.8112\n",
      "Epoch 482/1200\n",
      "1137/1137 [==============================] - 1s 543us/step - loss: 20928.1866 - val_loss: 33559.0605\n",
      "Epoch 483/1200\n",
      "1137/1137 [==============================] - 1s 545us/step - loss: 21479.2207 - val_loss: 33791.1747\n",
      "Epoch 484/1200\n",
      "1137/1137 [==============================] - 1s 597us/step - loss: 20807.7542 - val_loss: 33031.6590\n",
      "Epoch 485/1200\n",
      "1137/1137 [==============================] - 1s 543us/step - loss: 20280.4308 - val_loss: 35782.6106\n",
      "Epoch 486/1200\n",
      "1137/1137 [==============================] - 1s 582us/step - loss: 20859.1645 - val_loss: 33526.1152\n",
      "Epoch 487/1200\n",
      "1137/1137 [==============================] - 1s 531us/step - loss: 20427.8982 - val_loss: 33451.8215\n",
      "Epoch 488/1200\n",
      "1137/1137 [==============================] - 1s 535us/step - loss: 20723.9399 - val_loss: 33291.8887\n",
      "Epoch 489/1200\n",
      "1137/1137 [==============================] - 1s 573us/step - loss: 20405.8839 - val_loss: 33791.3984\n",
      "Epoch 490/1200\n",
      "1137/1137 [==============================] - 1s 564us/step - loss: 21360.1362 - val_loss: 32977.0659\n",
      "Epoch 491/1200\n",
      "1137/1137 [==============================] - 1s 551us/step - loss: 20413.9363 - val_loss: 32484.6394\n",
      "Epoch 492/1200\n",
      "1137/1137 [==============================] - 1s 579us/step - loss: 20877.9917 - val_loss: 32975.9888\n",
      "Epoch 493/1200\n",
      "1137/1137 [==============================] - 1s 543us/step - loss: 20248.2406 - val_loss: 32822.9084\n",
      "Epoch 494/1200\n",
      "1137/1137 [==============================] - 1s 586us/step - loss: 20517.3349 - val_loss: 32404.6437\n",
      "Epoch 495/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 1s 544us/step - loss: 20170.2182 - val_loss: 33316.3722\n",
      "Epoch 496/1200\n",
      "1137/1137 [==============================] - 1s 568us/step - loss: 20138.2388 - val_loss: 33883.1193\n",
      "Epoch 497/1200\n",
      "1137/1137 [==============================] - 1s 585us/step - loss: 20962.7528 - val_loss: 32889.7699\n",
      "Epoch 498/1200\n",
      "1137/1137 [==============================] - 1s 561us/step - loss: 20024.6986 - val_loss: 33266.2194\n",
      "Epoch 499/1200\n",
      "1137/1137 [==============================] - 1s 525us/step - loss: 20836.8143 - val_loss: 32556.6902\n",
      "Epoch 500/1200\n",
      "1137/1137 [==============================] - 1s 508us/step - loss: 20197.5057 - val_loss: 34057.6933\n",
      "Epoch 501/1200\n",
      "1137/1137 [==============================] - 1s 521us/step - loss: 20283.7478 - val_loss: 32645.8965\n",
      "Epoch 502/1200\n",
      "1137/1137 [==============================] - 1s 519us/step - loss: 20084.5430 - val_loss: 32874.0335\n",
      "Epoch 503/1200\n",
      "1137/1137 [==============================] - 1s 529us/step - loss: 20110.6517 - val_loss: 32759.7557\n",
      "Epoch 504/1200\n",
      "1137/1137 [==============================] - 1s 574us/step - loss: 20576.1352 - val_loss: 34329.5555\n",
      "Epoch 505/1200\n",
      "1137/1137 [==============================] - 1s 561us/step - loss: 20320.6062 - val_loss: 32168.4351\n",
      "Epoch 506/1200\n",
      "1137/1137 [==============================] - 1s 533us/step - loss: 20011.8319 - val_loss: 33948.9052\n",
      "Epoch 507/1200\n",
      "1137/1137 [==============================] - 1s 589us/step - loss: 20534.8183 - val_loss: 32515.8946\n",
      "Epoch 508/1200\n",
      "1137/1137 [==============================] - 1s 569us/step - loss: 20595.9834 - val_loss: 32832.7520\n",
      "Epoch 509/1200\n",
      "1137/1137 [==============================] - 1s 549us/step - loss: 20330.5475 - val_loss: 32668.9395\n",
      "Epoch 510/1200\n",
      "1137/1137 [==============================] - 1s 554us/step - loss: 20423.2070 - val_loss: 33504.7859\n",
      "Epoch 511/1200\n",
      "1137/1137 [==============================] - 1s 589us/step - loss: 20170.5857 - val_loss: 32111.4983\n",
      "Epoch 512/1200\n",
      "1137/1137 [==============================] - 1s 594us/step - loss: 20103.0133 - val_loss: 32358.7238\n",
      "Epoch 513/1200\n",
      "1137/1137 [==============================] - 1s 591us/step - loss: 19892.1434 - val_loss: 33088.7697\n",
      "Epoch 514/1200\n",
      "1137/1137 [==============================] - 1s 584us/step - loss: 20182.0449 - val_loss: 34347.5753\n",
      "Epoch 515/1200\n",
      "1137/1137 [==============================] - 1s 564us/step - loss: 20312.4113 - val_loss: 31743.0512\n",
      "Epoch 516/1200\n",
      "1137/1137 [==============================] - 1s 570us/step - loss: 20034.5064 - val_loss: 32586.5933\n",
      "Epoch 517/1200\n",
      "1137/1137 [==============================] - 1s 525us/step - loss: 20335.8966 - val_loss: 32377.6188\n",
      "Epoch 518/1200\n",
      "1137/1137 [==============================] - 1s 555us/step - loss: 20299.6692 - val_loss: 33446.9911\n",
      "Epoch 519/1200\n",
      "1137/1137 [==============================] - 1s 529us/step - loss: 20586.2658 - val_loss: 31822.0140\n",
      "Epoch 520/1200\n",
      "1137/1137 [==============================] - 1s 556us/step - loss: 20063.9604 - val_loss: 32381.9567\n",
      "Epoch 521/1200\n",
      "1137/1137 [==============================] - 1s 580us/step - loss: 19949.8582 - val_loss: 34862.8276\n",
      "Epoch 522/1200\n",
      "1137/1137 [==============================] - 1s 518us/step - loss: 19898.5281 - val_loss: 32651.9143\n",
      "Epoch 523/1200\n",
      "1137/1137 [==============================] - 1s 525us/step - loss: 19763.4471 - val_loss: 34159.2356\n",
      "Epoch 524/1200\n",
      "1137/1137 [==============================] - 1s 535us/step - loss: 20087.3813 - val_loss: 32179.1506\n",
      "Epoch 525/1200\n",
      "1137/1137 [==============================] - 1s 553us/step - loss: 19935.7771 - val_loss: 33012.7420\n",
      "Epoch 526/1200\n",
      "1137/1137 [==============================] - 1s 537us/step - loss: 20395.4040 - val_loss: 32342.4587\n",
      "Epoch 527/1200\n",
      "1137/1137 [==============================] - 1s 536us/step - loss: 19866.3035 - val_loss: 32745.3478\n",
      "Epoch 528/1200\n",
      "1137/1137 [==============================] - 1s 587us/step - loss: 20647.8141 - val_loss: 33639.1598\n",
      "Epoch 529/1200\n",
      "1137/1137 [==============================] - 1s 594us/step - loss: 19983.8045 - val_loss: 31654.0565\n",
      "Epoch 530/1200\n",
      "1137/1137 [==============================] - 1s 536us/step - loss: 19987.2676 - val_loss: 32587.7842\n",
      "Epoch 531/1200\n",
      "1137/1137 [==============================] - 1s 538us/step - loss: 20656.8981 - val_loss: 33540.7634\n",
      "Epoch 532/1200\n",
      "1137/1137 [==============================] - 1s 541us/step - loss: 19307.6677 - val_loss: 33480.2895\n",
      "Epoch 533/1200\n",
      "1137/1137 [==============================] - 1s 530us/step - loss: 20025.1593 - val_loss: 33407.5126\n",
      "Epoch 534/1200\n",
      "1137/1137 [==============================] - 1s 577us/step - loss: 20596.1138 - val_loss: 31809.8310\n",
      "Epoch 535/1200\n",
      "1137/1137 [==============================] - 1s 546us/step - loss: 20159.4954 - val_loss: 32271.9329\n",
      "Epoch 536/1200\n",
      "1137/1137 [==============================] - 1s 556us/step - loss: 19325.4907 - val_loss: 33622.7616\n",
      "Epoch 537/1200\n",
      "1137/1137 [==============================] - 1s 535us/step - loss: 20264.3045 - val_loss: 32441.4940\n",
      "Epoch 538/1200\n",
      "1137/1137 [==============================] - 1s 597us/step - loss: 21245.6197 - val_loss: 33876.0086\n",
      "Epoch 539/1200\n",
      "1137/1137 [==============================] - 1s 590us/step - loss: 19664.4401 - val_loss: 31778.7722\n",
      "Epoch 540/1200\n",
      "1137/1137 [==============================] - 1s 627us/step - loss: 20538.4868 - val_loss: 33146.1632\n",
      "Epoch 541/1200\n",
      "1137/1137 [==============================] - 1s 601us/step - loss: 20278.9686 - val_loss: 33011.1159\n",
      "Epoch 542/1200\n",
      "1137/1137 [==============================] - 1s 564us/step - loss: 19870.3395 - val_loss: 33037.9837\n",
      "Epoch 543/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 19638.1933 - val_loss: 32805.7789\n",
      "Epoch 544/1200\n",
      "1137/1137 [==============================] - 1s 538us/step - loss: 20560.9140 - val_loss: 32296.7338\n",
      "Epoch 545/1200\n",
      "1137/1137 [==============================] - 1s 582us/step - loss: 19608.2419 - val_loss: 33524.2875\n",
      "Epoch 546/1200\n",
      "1137/1137 [==============================] - 1s 580us/step - loss: 19646.4757 - val_loss: 31681.1358\n",
      "Epoch 547/1200\n",
      "1137/1137 [==============================] - 1s 591us/step - loss: 19868.5156 - val_loss: 32474.8217\n",
      "Epoch 548/1200\n",
      "1137/1137 [==============================] - 1s 592us/step - loss: 19598.8202 - val_loss: 31579.3564\n",
      "Epoch 549/1200\n",
      "1137/1137 [==============================] - 1s 563us/step - loss: 20344.1764 - val_loss: 32138.1775\n",
      "Epoch 550/1200\n",
      "1137/1137 [==============================] - 1s 564us/step - loss: 19461.3667 - val_loss: 32696.1841\n",
      "Epoch 551/1200\n",
      "1137/1137 [==============================] - 1s 600us/step - loss: 20432.6852 - val_loss: 31573.8807\n",
      "Epoch 552/1200\n",
      "1137/1137 [==============================] - 1s 563us/step - loss: 19318.6739 - val_loss: 32827.6440\n",
      "Epoch 553/1200\n",
      "1137/1137 [==============================] - 1s 536us/step - loss: 19760.4294 - val_loss: 31452.6249\n",
      "Epoch 554/1200\n",
      "1137/1137 [==============================] - 1s 547us/step - loss: 19447.7601 - val_loss: 31478.1909\n",
      "Epoch 555/1200\n",
      "1137/1137 [==============================] - 1s 527us/step - loss: 20045.8714 - val_loss: 32627.5374\n",
      "Epoch 556/1200\n",
      "1137/1137 [==============================] - 1s 524us/step - loss: 19426.4246 - val_loss: 37678.1509\n",
      "Epoch 557/1200\n",
      "1137/1137 [==============================] - 1s 543us/step - loss: 20684.0121 - val_loss: 32895.3527\n",
      "Epoch 558/1200\n",
      "1137/1137 [==============================] - 1s 587us/step - loss: 19836.8892 - val_loss: 31963.9828\n",
      "Epoch 559/1200\n",
      "1137/1137 [==============================] - 1s 596us/step - loss: 20138.0012 - val_loss: 33314.9560\n",
      "Epoch 560/1200\n",
      "1137/1137 [==============================] - 1s 589us/step - loss: 19041.0805 - val_loss: 31667.0910\n",
      "Epoch 561/1200\n",
      "1137/1137 [==============================] - 1s 559us/step - loss: 19311.3750 - val_loss: 33270.4458\n",
      "Epoch 562/1200\n",
      "1137/1137 [==============================] - 1s 533us/step - loss: 19789.0696 - val_loss: 32059.9739\n",
      "Epoch 563/1200\n",
      "1137/1137 [==============================] - 1s 528us/step - loss: 19204.3266 - val_loss: 32264.8811\n",
      "Epoch 564/1200\n",
      "1137/1137 [==============================] - 1s 542us/step - loss: 21137.5650 - val_loss: 34455.7643\n",
      "Epoch 565/1200\n",
      "1137/1137 [==============================] - 1s 540us/step - loss: 19697.2224 - val_loss: 32013.3215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 566/1200\n",
      "1137/1137 [==============================] - 1s 524us/step - loss: 19030.3816 - val_loss: 32297.8196\n",
      "Epoch 567/1200\n",
      "1137/1137 [==============================] - 1s 519us/step - loss: 19282.9346 - val_loss: 31226.9783\n",
      "Epoch 568/1200\n",
      "1137/1137 [==============================] - 1s 562us/step - loss: 19050.2406 - val_loss: 31872.1372\n",
      "Epoch 569/1200\n",
      "1137/1137 [==============================] - 1s 548us/step - loss: 19966.0588 - val_loss: 32135.8336\n",
      "Epoch 570/1200\n",
      "1137/1137 [==============================] - 1s 592us/step - loss: 19596.3987 - val_loss: 31664.4848\n",
      "Epoch 571/1200\n",
      "1137/1137 [==============================] - 1s 547us/step - loss: 19517.8949 - val_loss: 32294.3261\n",
      "Epoch 572/1200\n",
      "1137/1137 [==============================] - 1s 521us/step - loss: 18981.2948 - val_loss: 33595.7755\n",
      "Epoch 573/1200\n",
      "1137/1137 [==============================] - 1s 536us/step - loss: 19559.2490 - val_loss: 32466.3949\n",
      "Epoch 574/1200\n",
      "1137/1137 [==============================] - 1s 572us/step - loss: 19137.1587 - val_loss: 37305.3485\n",
      "Epoch 575/1200\n",
      "1137/1137 [==============================] - 1s 543us/step - loss: 19202.7140 - val_loss: 31658.7985\n",
      "Epoch 576/1200\n",
      "1137/1137 [==============================] - 1s 578us/step - loss: 19377.8312 - val_loss: 33420.5731\n",
      "Epoch 577/1200\n",
      "1137/1137 [==============================] - 1s 579us/step - loss: 18996.2315 - val_loss: 31242.7430\n",
      "Epoch 578/1200\n",
      "1137/1137 [==============================] - 1s 599us/step - loss: 19258.3340 - val_loss: 32499.7035\n",
      "Epoch 579/1200\n",
      "1137/1137 [==============================] - 1s 553us/step - loss: 19449.2241 - val_loss: 32422.1800\n",
      "Epoch 580/1200\n",
      "1137/1137 [==============================] - 1s 549us/step - loss: 18900.3450 - val_loss: 34003.5161\n",
      "Epoch 581/1200\n",
      "1137/1137 [==============================] - 1s 584us/step - loss: 18914.5178 - val_loss: 32045.1495\n",
      "Epoch 582/1200\n",
      "1137/1137 [==============================] - 1s 561us/step - loss: 19311.6200 - val_loss: 31882.6671\n",
      "Epoch 583/1200\n",
      "1137/1137 [==============================] - 1s 587us/step - loss: 18868.4362 - val_loss: 31048.2264\n",
      "Epoch 584/1200\n",
      "1137/1137 [==============================] - 1s 588us/step - loss: 18892.9304 - val_loss: 31628.0095\n",
      "Epoch 585/1200\n",
      "1137/1137 [==============================] - 1s 583us/step - loss: 19064.5995 - val_loss: 31405.5385\n",
      "Epoch 586/1200\n",
      "1137/1137 [==============================] - 1s 544us/step - loss: 19489.4263 - val_loss: 33051.1474\n",
      "Epoch 587/1200\n",
      "1137/1137 [==============================] - 1s 525us/step - loss: 18891.1523 - val_loss: 32192.1355\n",
      "Epoch 588/1200\n",
      "1137/1137 [==============================] - 1s 593us/step - loss: 19013.9531 - val_loss: 32063.5154\n",
      "Epoch 589/1200\n",
      "1137/1137 [==============================] - 1s 549us/step - loss: 19100.6300 - val_loss: 31015.5459\n",
      "Epoch 590/1200\n",
      "1137/1137 [==============================] - 1s 558us/step - loss: 19524.6455 - val_loss: 34285.6867\n",
      "Epoch 591/1200\n",
      "1137/1137 [==============================] - 1s 601us/step - loss: 19479.2419 - val_loss: 31920.5548\n",
      "Epoch 592/1200\n",
      "1137/1137 [==============================] - 1s 542us/step - loss: 19074.1056 - val_loss: 31343.7398\n",
      "Epoch 593/1200\n",
      "1137/1137 [==============================] - 1s 561us/step - loss: 19570.8081 - val_loss: 31346.1867\n",
      "Epoch 594/1200\n",
      "1137/1137 [==============================] - 1s 530us/step - loss: 18810.2606 - val_loss: 31803.8804\n",
      "Epoch 595/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 18771.6256 - val_loss: 31685.2389\n",
      "Epoch 596/1200\n",
      "1137/1137 [==============================] - 1s 550us/step - loss: 19475.8257 - val_loss: 31761.7155\n",
      "Epoch 597/1200\n",
      "1137/1137 [==============================] - 1s 587us/step - loss: 18906.6024 - val_loss: 31348.9189\n",
      "Epoch 598/1200\n",
      "1137/1137 [==============================] - 1s 541us/step - loss: 18922.8364 - val_loss: 34767.8602\n",
      "Epoch 599/1200\n",
      "1137/1137 [==============================] - 1s 576us/step - loss: 18894.6596 - val_loss: 31881.7930\n",
      "Epoch 600/1200\n",
      "1137/1137 [==============================] - 1s 552us/step - loss: 19570.8761 - val_loss: 33056.6532\n",
      "Epoch 601/1200\n",
      "1137/1137 [==============================] - 1s 591us/step - loss: 18758.1760 - val_loss: 32583.8975\n",
      "Epoch 602/1200\n",
      "1137/1137 [==============================] - 1s 544us/step - loss: 19746.9752 - val_loss: 31706.5539\n",
      "Epoch 603/1200\n",
      "1137/1137 [==============================] - 1s 540us/step - loss: 18908.8132 - val_loss: 31355.4082\n",
      "Epoch 604/1200\n",
      "1137/1137 [==============================] - 1s 529us/step - loss: 18486.7917 - val_loss: 31212.8890\n",
      "Epoch 605/1200\n",
      "1137/1137 [==============================] - 1s 566us/step - loss: 18168.3299 - val_loss: 32346.3459\n",
      "Epoch 606/1200\n",
      "1137/1137 [==============================] - 1s 571us/step - loss: 18782.2802 - val_loss: 31035.0399\n",
      "Epoch 607/1200\n",
      "1137/1137 [==============================] - 1s 561us/step - loss: 19569.8755 - val_loss: 34117.6053\n",
      "Epoch 608/1200\n",
      "1137/1137 [==============================] - 1s 569us/step - loss: 18645.0505 - val_loss: 32460.1327\n",
      "Epoch 609/1200\n",
      "1137/1137 [==============================] - 1s 540us/step - loss: 19226.6543 - val_loss: 30558.5371\n",
      "Epoch 610/1200\n",
      "1137/1137 [==============================] - 1s 582us/step - loss: 19036.0182 - val_loss: 31249.1947\n",
      "Epoch 611/1200\n",
      "1137/1137 [==============================] - 1s 573us/step - loss: 18877.3915 - val_loss: 31083.9554\n",
      "Epoch 612/1200\n",
      "1137/1137 [==============================] - 1s 592us/step - loss: 18183.7122 - val_loss: 32031.0657\n",
      "Epoch 613/1200\n",
      "1137/1137 [==============================] - 1s 606us/step - loss: 17873.3889 - val_loss: 31074.3843\n",
      "Epoch 614/1200\n",
      "1137/1137 [==============================] - 1s 597us/step - loss: 18526.5286 - val_loss: 31924.7834\n",
      "Epoch 615/1200\n",
      "1137/1137 [==============================] - 1s 566us/step - loss: 19971.0913 - val_loss: 31847.5862\n",
      "Epoch 616/1200\n",
      "1137/1137 [==============================] - 1s 584us/step - loss: 18602.2555 - val_loss: 31086.8150\n",
      "Epoch 617/1200\n",
      "1137/1137 [==============================] - 1s 585us/step - loss: 18850.3149 - val_loss: 31514.3689\n",
      "Epoch 618/1200\n",
      "1137/1137 [==============================] - 1s 574us/step - loss: 19029.5773 - val_loss: 30372.1603\n",
      "Epoch 619/1200\n",
      "1137/1137 [==============================] - 1s 538us/step - loss: 18780.3597 - val_loss: 31245.7365\n",
      "Epoch 620/1200\n",
      "1137/1137 [==============================] - 1s 543us/step - loss: 18339.0010 - val_loss: 30530.4081\n",
      "Epoch 621/1200\n",
      "1137/1137 [==============================] - 1s 562us/step - loss: 18545.8183 - val_loss: 31941.9615\n",
      "Epoch 622/1200\n",
      "1137/1137 [==============================] - 1s 574us/step - loss: 18833.9602 - val_loss: 31281.5226\n",
      "Epoch 623/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 19081.1937 - val_loss: 31049.1826\n",
      "Epoch 624/1200\n",
      "1137/1137 [==============================] - 1s 550us/step - loss: 18597.7180 - val_loss: 30642.0981\n",
      "Epoch 625/1200\n",
      "1137/1137 [==============================] - 1s 531us/step - loss: 18478.0788 - val_loss: 32076.0819\n",
      "Epoch 626/1200\n",
      "1137/1137 [==============================] - 1s 561us/step - loss: 18210.2470 - val_loss: 31377.4927\n",
      "Epoch 627/1200\n",
      "1137/1137 [==============================] - 1s 542us/step - loss: 18846.6508 - val_loss: 30783.5067\n",
      "Epoch 628/1200\n",
      "1137/1137 [==============================] - 1s 552us/step - loss: 19093.5143 - val_loss: 30386.4754\n",
      "Epoch 629/1200\n",
      "1137/1137 [==============================] - 1s 541us/step - loss: 18845.8842 - val_loss: 32274.3649\n",
      "Epoch 630/1200\n",
      "1137/1137 [==============================] - 1s 554us/step - loss: 18289.9323 - val_loss: 30582.7365\n",
      "Epoch 631/1200\n",
      "1137/1137 [==============================] - 1s 597us/step - loss: 18475.8065 - val_loss: 30742.5347\n",
      "Epoch 632/1200\n",
      "1137/1137 [==============================] - 1s 579us/step - loss: 17982.9576 - val_loss: 30315.3937\n",
      "Epoch 633/1200\n",
      "1137/1137 [==============================] - 1s 578us/step - loss: 18438.9344 - val_loss: 30550.5232\n",
      "Epoch 634/1200\n",
      "1137/1137 [==============================] - 1s 543us/step - loss: 20295.6568 - val_loss: 30761.5467\n",
      "Epoch 635/1200\n",
      "1137/1137 [==============================] - 1s 542us/step - loss: 18520.8738 - val_loss: 31170.2344\n",
      "Epoch 636/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 1s 582us/step - loss: 18246.7553 - val_loss: 30569.4653\n",
      "Epoch 637/1200\n",
      "1137/1137 [==============================] - 1s 525us/step - loss: 18046.6713 - val_loss: 30650.8663\n",
      "Epoch 638/1200\n",
      "1137/1137 [==============================] - 1s 562us/step - loss: 18880.4316 - val_loss: 30269.6055\n",
      "Epoch 639/1200\n",
      "1137/1137 [==============================] - 1s 540us/step - loss: 19157.0331 - val_loss: 30390.4011\n",
      "Epoch 640/1200\n",
      "1137/1137 [==============================] - 1s 573us/step - loss: 18876.4860 - val_loss: 30812.2442\n",
      "Epoch 641/1200\n",
      "1137/1137 [==============================] - 1s 567us/step - loss: 18430.6359 - val_loss: 34643.6363\n",
      "Epoch 642/1200\n",
      "1137/1137 [==============================] - 1s 522us/step - loss: 19387.4291 - val_loss: 30267.7451\n",
      "Epoch 643/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 18153.5493 - val_loss: 30523.5755\n",
      "Epoch 644/1200\n",
      "1137/1137 [==============================] - 1s 525us/step - loss: 18463.4350 - val_loss: 30703.3990\n",
      "Epoch 645/1200\n",
      "1137/1137 [==============================] - 1s 537us/step - loss: 18483.8288 - val_loss: 30255.0278\n",
      "Epoch 646/1200\n",
      "1137/1137 [==============================] - 1s 603us/step - loss: 18626.9765 - val_loss: 30930.0591\n",
      "Epoch 647/1200\n",
      "1137/1137 [==============================] - 1s 702us/step - loss: 18992.2931 - val_loss: 31414.7184\n",
      "Epoch 648/1200\n",
      "1137/1137 [==============================] - 1s 688us/step - loss: 17961.9450 - val_loss: 30885.6725\n",
      "Epoch 649/1200\n",
      "1137/1137 [==============================] - 1s 653us/step - loss: 18711.3211 - val_loss: 31496.5272\n",
      "Epoch 650/1200\n",
      "1137/1137 [==============================] - 1s 694us/step - loss: 17990.7579 - val_loss: 30803.2156\n",
      "Epoch 651/1200\n",
      "1137/1137 [==============================] - 1s 591us/step - loss: 18516.5867 - val_loss: 30537.2499\n",
      "Epoch 652/1200\n",
      "1137/1137 [==============================] - 1s 582us/step - loss: 18323.2955 - val_loss: 30368.6528\n",
      "Epoch 653/1200\n",
      "1137/1137 [==============================] - 1s 575us/step - loss: 18352.0794 - val_loss: 30139.3481\n",
      "Epoch 654/1200\n",
      "1137/1137 [==============================] - 1s 525us/step - loss: 18677.7397 - val_loss: 31045.2926\n",
      "Epoch 655/1200\n",
      "1137/1137 [==============================] - 1s 571us/step - loss: 18334.4966 - val_loss: 32283.3622\n",
      "Epoch 656/1200\n",
      "1137/1137 [==============================] - 1s 572us/step - loss: 18362.5343 - val_loss: 30753.5750\n",
      "Epoch 657/1200\n",
      "1137/1137 [==============================] - 1s 571us/step - loss: 18180.3646 - val_loss: 31976.3407\n",
      "Epoch 658/1200\n",
      "1137/1137 [==============================] - 1s 575us/step - loss: 18108.7126 - val_loss: 30255.6091\n",
      "Epoch 659/1200\n",
      "1137/1137 [==============================] - 1s 531us/step - loss: 18169.5448 - val_loss: 30023.0036\n",
      "Epoch 660/1200\n",
      "1137/1137 [==============================] - 1s 543us/step - loss: 18907.2754 - val_loss: 30337.7050\n",
      "Epoch 661/1200\n",
      "1137/1137 [==============================] - 1s 532us/step - loss: 19384.3307 - val_loss: 30256.6931\n",
      "Epoch 662/1200\n",
      "1137/1137 [==============================] - 1s 562us/step - loss: 18309.3020 - val_loss: 30586.7451\n",
      "Epoch 663/1200\n",
      "1137/1137 [==============================] - 1s 580us/step - loss: 18403.2560 - val_loss: 30008.6424\n",
      "Epoch 664/1200\n",
      "1137/1137 [==============================] - 1s 548us/step - loss: 18105.0444 - val_loss: 29621.3160\n",
      "Epoch 665/1200\n",
      "1137/1137 [==============================] - 1s 620us/step - loss: 17666.9600 - val_loss: 30004.8398\n",
      "Epoch 666/1200\n",
      "1137/1137 [==============================] - 1s 604us/step - loss: 18085.0974 - val_loss: 30673.9341\n",
      "Epoch 667/1200\n",
      "1137/1137 [==============================] - 1s 590us/step - loss: 18645.7038 - val_loss: 30121.8508\n",
      "Epoch 668/1200\n",
      "1137/1137 [==============================] - 1s 553us/step - loss: 18308.1855 - val_loss: 31951.4430\n",
      "Epoch 669/1200\n",
      "1137/1137 [==============================] - 1s 528us/step - loss: 17375.4385 - val_loss: 29791.3514\n",
      "Epoch 670/1200\n",
      "1137/1137 [==============================] - 1s 587us/step - loss: 18123.5709 - val_loss: 30152.0294\n",
      "Epoch 671/1200\n",
      "1137/1137 [==============================] - 1s 568us/step - loss: 17551.0810 - val_loss: 30875.8065\n",
      "Epoch 672/1200\n",
      "1137/1137 [==============================] - 1s 575us/step - loss: 17760.8167 - val_loss: 29986.4267\n",
      "Epoch 673/1200\n",
      "1137/1137 [==============================] - 1s 584us/step - loss: 17933.6724 - val_loss: 29840.9417\n",
      "Epoch 674/1200\n",
      "1137/1137 [==============================] - 1s 591us/step - loss: 18111.2946 - val_loss: 30640.5404\n",
      "Epoch 675/1200\n",
      "1137/1137 [==============================] - 1s 535us/step - loss: 18093.2971 - val_loss: 30968.6069\n",
      "Epoch 676/1200\n",
      "1137/1137 [==============================] - 1s 552us/step - loss: 17995.8103 - val_loss: 29687.5801\n",
      "Epoch 677/1200\n",
      "1137/1137 [==============================] - 1s 597us/step - loss: 18166.4615 - val_loss: 29748.2525\n",
      "Epoch 678/1200\n",
      "1137/1137 [==============================] - 1s 595us/step - loss: 17781.8068 - val_loss: 31308.0464\n",
      "Epoch 679/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 18349.9377 - val_loss: 29955.1581\n",
      "Epoch 680/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 17827.8227 - val_loss: 29598.0612\n",
      "Epoch 681/1200\n",
      "1137/1137 [==============================] - 1s 528us/step - loss: 18250.7019 - val_loss: 30875.5223\n",
      "Epoch 682/1200\n",
      "1137/1137 [==============================] - 1s 605us/step - loss: 18258.2107 - val_loss: 29343.8019\n",
      "Epoch 683/1200\n",
      "1137/1137 [==============================] - 1s 596us/step - loss: 17672.4065 - val_loss: 31925.2072\n",
      "Epoch 684/1200\n",
      "1137/1137 [==============================] - 1s 594us/step - loss: 18054.8414 - val_loss: 30860.8517\n",
      "Epoch 685/1200\n",
      "1137/1137 [==============================] - 1s 574us/step - loss: 18390.8955 - val_loss: 29650.3106\n",
      "Epoch 686/1200\n",
      "1137/1137 [==============================] - 1s 541us/step - loss: 18377.7375 - val_loss: 30095.5118\n",
      "Epoch 687/1200\n",
      "1137/1137 [==============================] - 1s 557us/step - loss: 18484.2940 - val_loss: 30485.0646\n",
      "Epoch 688/1200\n",
      "1137/1137 [==============================] - 1s 576us/step - loss: 18820.3273 - val_loss: 29586.2272\n",
      "Epoch 689/1200\n",
      "1137/1137 [==============================] - 1s 558us/step - loss: 17493.8737 - val_loss: 29486.1188\n",
      "Epoch 690/1200\n",
      "1137/1137 [==============================] - 1s 538us/step - loss: 17773.9423 - val_loss: 29797.6265\n",
      "Epoch 691/1200\n",
      "1137/1137 [==============================] - 1s 580us/step - loss: 18526.2763 - val_loss: 29881.1168\n",
      "Epoch 692/1200\n",
      "1137/1137 [==============================] - 1s 575us/step - loss: 18114.5409 - val_loss: 29670.9440\n",
      "Epoch 693/1200\n",
      "1137/1137 [==============================] - 1s 577us/step - loss: 18063.6789 - val_loss: 29479.7520\n",
      "Epoch 694/1200\n",
      "1137/1137 [==============================] - 1s 563us/step - loss: 18147.0599 - val_loss: 30108.3122\n",
      "Epoch 695/1200\n",
      "1137/1137 [==============================] - 1s 604us/step - loss: 17927.7216 - val_loss: 29606.6991\n",
      "Epoch 696/1200\n",
      "1137/1137 [==============================] - 1s 553us/step - loss: 17674.1942 - val_loss: 29865.1658\n",
      "Epoch 697/1200\n",
      "1137/1137 [==============================] - 1s 547us/step - loss: 18381.1943 - val_loss: 29476.6922\n",
      "Epoch 698/1200\n",
      "1137/1137 [==============================] - 1s 605us/step - loss: 17708.0182 - val_loss: 29093.4677\n",
      "Epoch 699/1200\n",
      "1137/1137 [==============================] - 1s 601us/step - loss: 17973.4123 - val_loss: 29467.7565\n",
      "Epoch 700/1200\n",
      "1137/1137 [==============================] - 1s 568us/step - loss: 18316.9156 - val_loss: 29515.1918\n",
      "Epoch 701/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 18417.7574 - val_loss: 30404.6874\n",
      "Epoch 702/1200\n",
      "1137/1137 [==============================] - 1s 576us/step - loss: 18399.4628 - val_loss: 29810.0227\n",
      "Epoch 703/1200\n",
      "1137/1137 [==============================] - 1s 554us/step - loss: 17380.5425 - val_loss: 29675.7746\n",
      "Epoch 704/1200\n",
      "1137/1137 [==============================] - 1s 577us/step - loss: 18365.8637 - val_loss: 29598.5750\n",
      "Epoch 705/1200\n",
      "1137/1137 [==============================] - 1s 606us/step - loss: 18470.2400 - val_loss: 30037.6975\n",
      "Epoch 706/1200\n",
      "1137/1137 [==============================] - 1s 548us/step - loss: 17751.8957 - val_loss: 29789.6879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 707/1200\n",
      "1137/1137 [==============================] - 1s 546us/step - loss: 17724.7521 - val_loss: 29590.0006\n",
      "Epoch 708/1200\n",
      "1137/1137 [==============================] - 1s 536us/step - loss: 17941.7056 - val_loss: 29573.0544\n",
      "Epoch 709/1200\n",
      "1137/1137 [==============================] - 1s 583us/step - loss: 17438.1399 - val_loss: 29043.5934\n",
      "Epoch 710/1200\n",
      "1137/1137 [==============================] - 1s 613us/step - loss: 17563.0673 - val_loss: 29519.1571\n",
      "Epoch 711/1200\n",
      "1137/1137 [==============================] - 1s 593us/step - loss: 18791.0222 - val_loss: 29133.7525\n",
      "Epoch 712/1200\n",
      "1137/1137 [==============================] - 1s 535us/step - loss: 17701.0223 - val_loss: 29082.9157\n",
      "Epoch 713/1200\n",
      "1137/1137 [==============================] - 1s 552us/step - loss: 18038.5665 - val_loss: 29143.1792\n",
      "Epoch 714/1200\n",
      "1137/1137 [==============================] - 1s 529us/step - loss: 18145.4320 - val_loss: 31861.6020\n",
      "Epoch 715/1200\n",
      "1137/1137 [==============================] - 1s 566us/step - loss: 18198.1067 - val_loss: 29540.1691\n",
      "Epoch 716/1200\n",
      "1137/1137 [==============================] - 1s 536us/step - loss: 17651.2486 - val_loss: 29620.5329\n",
      "Epoch 717/1200\n",
      "1137/1137 [==============================] - 1s 544us/step - loss: 18420.3662 - val_loss: 30903.4425\n",
      "Epoch 718/1200\n",
      "1137/1137 [==============================] - 1s 570us/step - loss: 17722.6115 - val_loss: 28868.1750\n",
      "Epoch 719/1200\n",
      "1137/1137 [==============================] - 1s 545us/step - loss: 17015.4919 - val_loss: 28941.0582\n",
      "Epoch 720/1200\n",
      "1137/1137 [==============================] - 1s 546us/step - loss: 17177.3407 - val_loss: 30780.4330\n",
      "Epoch 721/1200\n",
      "1137/1137 [==============================] - 1s 537us/step - loss: 18083.9565 - val_loss: 30194.1691\n",
      "Epoch 722/1200\n",
      "1137/1137 [==============================] - 1s 557us/step - loss: 17257.5972 - val_loss: 30162.8724\n",
      "Epoch 723/1200\n",
      "1137/1137 [==============================] - 1s 579us/step - loss: 17414.1729 - val_loss: 30477.8516\n",
      "Epoch 724/1200\n",
      "1137/1137 [==============================] - 1s 593us/step - loss: 17675.3138 - val_loss: 28913.7973\n",
      "Epoch 725/1200\n",
      "1137/1137 [==============================] - 1s 572us/step - loss: 17439.4689 - val_loss: 29790.7723\n",
      "Epoch 726/1200\n",
      "1137/1137 [==============================] - 1s 582us/step - loss: 18050.9682 - val_loss: 29789.3612\n",
      "Epoch 727/1200\n",
      "1137/1137 [==============================] - 1s 592us/step - loss: 17234.1759 - val_loss: 28505.9781\n",
      "Epoch 728/1200\n",
      "1137/1137 [==============================] - 1s 553us/step - loss: 17389.6804 - val_loss: 31528.3468\n",
      "Epoch 729/1200\n",
      "1137/1137 [==============================] - 1s 537us/step - loss: 17604.0080 - val_loss: 29559.6929\n",
      "Epoch 730/1200\n",
      "1137/1137 [==============================] - 1s 538us/step - loss: 17096.0418 - val_loss: 30713.2349\n",
      "Epoch 731/1200\n",
      "1137/1137 [==============================] - 1s 565us/step - loss: 17231.5747 - val_loss: 28540.4306\n",
      "Epoch 732/1200\n",
      "1137/1137 [==============================] - 1s 541us/step - loss: 17184.7973 - val_loss: 28558.6002\n",
      "Epoch 733/1200\n",
      "1137/1137 [==============================] - 1s 534us/step - loss: 17130.6251 - val_loss: 29326.3230\n",
      "Epoch 734/1200\n",
      "1137/1137 [==============================] - 1s 569us/step - loss: 17160.3142 - val_loss: 28837.4581\n",
      "Epoch 735/1200\n",
      "1137/1137 [==============================] - 1s 588us/step - loss: 17393.3177 - val_loss: 31047.4102\n",
      "Epoch 736/1200\n",
      "1137/1137 [==============================] - 1s 591us/step - loss: 17383.8638 - val_loss: 29942.4033\n",
      "Epoch 737/1200\n",
      "1137/1137 [==============================] - 1s 600us/step - loss: 17660.4428 - val_loss: 29626.0850\n",
      "Epoch 738/1200\n",
      "1137/1137 [==============================] - 1s 533us/step - loss: 17602.0542 - val_loss: 28759.2391\n",
      "Epoch 739/1200\n",
      "1137/1137 [==============================] - 1s 561us/step - loss: 17704.9779 - val_loss: 28456.3426\n",
      "Epoch 740/1200\n",
      "1137/1137 [==============================] - 1s 580us/step - loss: 17728.0864 - val_loss: 29434.3982\n",
      "Epoch 741/1200\n",
      "1137/1137 [==============================] - 1s 565us/step - loss: 17637.9357 - val_loss: 28693.5068\n",
      "Epoch 742/1200\n",
      "1137/1137 [==============================] - 1s 519us/step - loss: 17277.0185 - val_loss: 29024.0868\n",
      "Epoch 743/1200\n",
      "1137/1137 [==============================] - 1s 568us/step - loss: 17099.7590 - val_loss: 31408.7071\n",
      "Epoch 744/1200\n",
      "1137/1137 [==============================] - 1s 573us/step - loss: 18370.1902 - val_loss: 29130.9068\n",
      "Epoch 745/1200\n",
      "1137/1137 [==============================] - 1s 583us/step - loss: 17233.4194 - val_loss: 30573.5182\n",
      "Epoch 746/1200\n",
      "1137/1137 [==============================] - 1s 536us/step - loss: 17546.1463 - val_loss: 28773.3249\n",
      "Epoch 747/1200\n",
      "1137/1137 [==============================] - 1s 543us/step - loss: 17184.8474 - val_loss: 29201.8144\n",
      "Epoch 748/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 18229.8868 - val_loss: 30442.2470\n",
      "Epoch 749/1200\n",
      "1137/1137 [==============================] - 1s 544us/step - loss: 18278.0446 - val_loss: 30445.3597\n",
      "Epoch 750/1200\n",
      "1137/1137 [==============================] - 1s 577us/step - loss: 17635.7590 - val_loss: 28615.2985\n",
      "Epoch 751/1200\n",
      "1137/1137 [==============================] - 1s 596us/step - loss: 18138.8472 - val_loss: 28789.7574\n",
      "Epoch 752/1200\n",
      "1137/1137 [==============================] - 1s 568us/step - loss: 17376.3468 - val_loss: 28808.8072\n",
      "Epoch 753/1200\n",
      "1137/1137 [==============================] - 1s 595us/step - loss: 17624.5218 - val_loss: 28961.5532\n",
      "Epoch 754/1200\n",
      "1137/1137 [==============================] - 1s 546us/step - loss: 17769.6857 - val_loss: 28350.3455\n",
      "Epoch 755/1200\n",
      "1137/1137 [==============================] - 1s 532us/step - loss: 17651.8244 - val_loss: 29261.1832\n",
      "Epoch 756/1200\n",
      "1137/1137 [==============================] - 1s 609us/step - loss: 17223.0389 - val_loss: 29244.3841\n",
      "Epoch 757/1200\n",
      "1137/1137 [==============================] - 1s 576us/step - loss: 17838.3580 - val_loss: 28378.7885\n",
      "Epoch 758/1200\n",
      "1137/1137 [==============================] - 1s 554us/step - loss: 17918.0706 - val_loss: 28785.1620\n",
      "Epoch 759/1200\n",
      "1137/1137 [==============================] - 1s 581us/step - loss: 17255.7161 - val_loss: 30061.2081\n",
      "Epoch 760/1200\n",
      "1137/1137 [==============================] - 1s 553us/step - loss: 17244.8306 - val_loss: 28417.1156\n",
      "Epoch 761/1200\n",
      "1137/1137 [==============================] - 1s 594us/step - loss: 18433.4723 - val_loss: 28309.3838\n",
      "Epoch 762/1200\n",
      "1137/1137 [==============================] - 1s 599us/step - loss: 17221.6316 - val_loss: 28933.6987\n",
      "Epoch 763/1200\n",
      "1137/1137 [==============================] - 1s 592us/step - loss: 17240.3526 - val_loss: 28790.2477\n",
      "Epoch 764/1200\n",
      "1137/1137 [==============================] - 1s 591us/step - loss: 17654.3902 - val_loss: 29412.6395\n",
      "Epoch 765/1200\n",
      "1137/1137 [==============================] - 1s 587us/step - loss: 17660.7694 - val_loss: 28407.5485\n",
      "Epoch 766/1200\n",
      "1137/1137 [==============================] - 1s 525us/step - loss: 16630.8173 - val_loss: 30757.0201\n",
      "Epoch 767/1200\n",
      "1137/1137 [==============================] - 1s 554us/step - loss: 18360.1336 - val_loss: 29369.3146\n",
      "Epoch 768/1200\n",
      "1137/1137 [==============================] - 1s 564us/step - loss: 17885.2472 - val_loss: 28994.2561\n",
      "Epoch 769/1200\n",
      "1137/1137 [==============================] - 1s 602us/step - loss: 16741.9621 - val_loss: 29028.4275\n",
      "Epoch 770/1200\n",
      "1137/1137 [==============================] - 1s 588us/step - loss: 17117.0948 - val_loss: 28474.0150\n",
      "Epoch 771/1200\n",
      "1137/1137 [==============================] - 1s 586us/step - loss: 17582.7935 - val_loss: 29453.0357\n",
      "Epoch 772/1200\n",
      "1137/1137 [==============================] - 1s 583us/step - loss: 17441.3019 - val_loss: 28736.6943\n",
      "Epoch 773/1200\n",
      "1137/1137 [==============================] - 1s 522us/step - loss: 18134.9768 - val_loss: 29303.0506\n",
      "Epoch 774/1200\n",
      "1137/1137 [==============================] - 1s 610us/step - loss: 17194.1337 - val_loss: 28700.2195\n",
      "Epoch 775/1200\n",
      "1137/1137 [==============================] - 1s 553us/step - loss: 17186.0981 - val_loss: 28262.2362\n",
      "Epoch 776/1200\n",
      "1137/1137 [==============================] - 1s 562us/step - loss: 17122.6678 - val_loss: 28427.1201\n",
      "Epoch 777/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 1s 594us/step - loss: 17677.3085 - val_loss: 28518.7126\n",
      "Epoch 778/1200\n",
      "1137/1137 [==============================] - 1s 572us/step - loss: 16939.7824 - val_loss: 29223.7181\n",
      "Epoch 779/1200\n",
      "1137/1137 [==============================] - 1s 547us/step - loss: 16433.0202 - val_loss: 28834.7350\n",
      "Epoch 780/1200\n",
      "1137/1137 [==============================] - 1s 589us/step - loss: 17479.5333 - val_loss: 28043.3155\n",
      "Epoch 781/1200\n",
      "1137/1137 [==============================] - 1s 562us/step - loss: 17255.7708 - val_loss: 29114.0119\n",
      "Epoch 782/1200\n",
      "1137/1137 [==============================] - 1s 514us/step - loss: 17955.2386 - val_loss: 27914.8339\n",
      "Epoch 783/1200\n",
      "1137/1137 [==============================] - 1s 590us/step - loss: 19059.4892 - val_loss: 28127.1107\n",
      "Epoch 784/1200\n",
      "1137/1137 [==============================] - 1s 616us/step - loss: 16952.2888 - val_loss: 28010.1740\n",
      "Epoch 785/1200\n",
      "1137/1137 [==============================] - 1s 568us/step - loss: 17050.1128 - val_loss: 28820.7928\n",
      "Epoch 786/1200\n",
      "1137/1137 [==============================] - 1s 579us/step - loss: 17110.9509 - val_loss: 28056.0717\n",
      "Epoch 787/1200\n",
      "1137/1137 [==============================] - 1s 556us/step - loss: 17176.7126 - val_loss: 28200.1119\n",
      "Epoch 788/1200\n",
      "1137/1137 [==============================] - 1s 571us/step - loss: 16642.7968 - val_loss: 28227.9032\n",
      "Epoch 789/1200\n",
      "1137/1137 [==============================] - 1s 554us/step - loss: 17046.0407 - val_loss: 29587.1629\n",
      "Epoch 790/1200\n",
      "1137/1137 [==============================] - 1s 566us/step - loss: 16542.9460 - val_loss: 27888.1612\n",
      "Epoch 791/1200\n",
      "1137/1137 [==============================] - 1s 581us/step - loss: 16553.7039 - val_loss: 28497.7335\n",
      "Epoch 792/1200\n",
      "1137/1137 [==============================] - 1s 549us/step - loss: 17317.9256 - val_loss: 27866.5880\n",
      "Epoch 793/1200\n",
      "1137/1137 [==============================] - 1s 547us/step - loss: 16789.2411 - val_loss: 27700.3618\n",
      "Epoch 794/1200\n",
      "1137/1137 [==============================] - 1s 566us/step - loss: 17870.0000 - val_loss: 30331.7689\n",
      "Epoch 795/1200\n",
      "1137/1137 [==============================] - 1s 582us/step - loss: 16524.4059 - val_loss: 28539.4964\n",
      "Epoch 796/1200\n",
      "1137/1137 [==============================] - 1s 591us/step - loss: 17131.1983 - val_loss: 27714.6776\n",
      "Epoch 797/1200\n",
      "1137/1137 [==============================] - 1s 592us/step - loss: 16748.3680 - val_loss: 28291.0626\n",
      "Epoch 798/1200\n",
      "1137/1137 [==============================] - 1s 594us/step - loss: 17655.7637 - val_loss: 28257.9311\n",
      "Epoch 799/1200\n",
      "1137/1137 [==============================] - 1s 545us/step - loss: 17189.8084 - val_loss: 28390.8578\n",
      "Epoch 800/1200\n",
      "1137/1137 [==============================] - 1s 541us/step - loss: 17030.6459 - val_loss: 27893.5760\n",
      "Epoch 801/1200\n",
      "1137/1137 [==============================] - 1s 540us/step - loss: 17173.1040 - val_loss: 28177.7643\n",
      "Epoch 802/1200\n",
      "1137/1137 [==============================] - 1s 565us/step - loss: 16977.3725 - val_loss: 28466.8676\n",
      "Epoch 803/1200\n",
      "1137/1137 [==============================] - 1s 545us/step - loss: 17177.0621 - val_loss: 27737.8486\n",
      "Epoch 804/1200\n",
      "1137/1137 [==============================] - 1s 596us/step - loss: 17575.6269 - val_loss: 27792.3210\n",
      "Epoch 805/1200\n",
      "1137/1137 [==============================] - 1s 572us/step - loss: 17204.6432 - val_loss: 29499.3659\n",
      "Epoch 806/1200\n",
      "1137/1137 [==============================] - 1s 558us/step - loss: 16746.0721 - val_loss: 27965.6858\n",
      "Epoch 807/1200\n",
      "1137/1137 [==============================] - 1s 592us/step - loss: 16620.2563 - val_loss: 28835.0801\n",
      "Epoch 808/1200\n",
      "1137/1137 [==============================] - 1s 532us/step - loss: 16700.6525 - val_loss: 27487.3247\n",
      "Epoch 809/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 17480.5605 - val_loss: 28483.8831\n",
      "Epoch 810/1200\n",
      "1137/1137 [==============================] - 1s 546us/step - loss: 17570.1287 - val_loss: 27761.3324\n",
      "Epoch 811/1200\n",
      "1137/1137 [==============================] - 1s 542us/step - loss: 16639.6670 - val_loss: 27657.3300\n",
      "Epoch 812/1200\n",
      "1137/1137 [==============================] - 1s 556us/step - loss: 17182.8396 - val_loss: 28730.3678\n",
      "Epoch 813/1200\n",
      "1137/1137 [==============================] - 1s 586us/step - loss: 16417.4958 - val_loss: 30273.4955\n",
      "Epoch 814/1200\n",
      "1137/1137 [==============================] - 1s 544us/step - loss: 16462.4217 - val_loss: 27716.3831\n",
      "Epoch 815/1200\n",
      "1137/1137 [==============================] - 1s 584us/step - loss: 16499.7890 - val_loss: 28464.3346\n",
      "Epoch 816/1200\n",
      "1137/1137 [==============================] - 1s 585us/step - loss: 16697.2058 - val_loss: 28159.1243\n",
      "Epoch 817/1200\n",
      "1137/1137 [==============================] - 1s 541us/step - loss: 16750.3656 - val_loss: 28069.1171\n",
      "Epoch 818/1200\n",
      "1137/1137 [==============================] - 1s 596us/step - loss: 16873.5664 - val_loss: 29430.8713\n",
      "Epoch 819/1200\n",
      "1137/1137 [==============================] - 1s 587us/step - loss: 17419.8716 - val_loss: 27740.6842\n",
      "Epoch 820/1200\n",
      "1137/1137 [==============================] - 1s 544us/step - loss: 16464.0965 - val_loss: 29834.1787\n",
      "Epoch 821/1200\n",
      "1137/1137 [==============================] - 1s 572us/step - loss: 16482.0375 - val_loss: 29092.2064\n",
      "Epoch 822/1200\n",
      "1137/1137 [==============================] - 1s 537us/step - loss: 16543.7059 - val_loss: 29159.9116\n",
      "Epoch 823/1200\n",
      "1137/1137 [==============================] - 1s 547us/step - loss: 16469.7181 - val_loss: 27730.8049\n",
      "Epoch 824/1200\n",
      "1137/1137 [==============================] - 1s 540us/step - loss: 16483.9567 - val_loss: 27680.4900\n",
      "Epoch 825/1200\n",
      "1137/1137 [==============================] - 1s 562us/step - loss: 16798.8624 - val_loss: 28999.8301\n",
      "Epoch 826/1200\n",
      "1137/1137 [==============================] - 1s 594us/step - loss: 16666.7074 - val_loss: 28682.9579\n",
      "Epoch 827/1200\n",
      "1137/1137 [==============================] - 1s 595us/step - loss: 16968.9631 - val_loss: 28656.1924\n",
      "Epoch 828/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 16410.8013 - val_loss: 30309.9149\n",
      "Epoch 829/1200\n",
      "1137/1137 [==============================] - 1s 548us/step - loss: 16243.2525 - val_loss: 27896.0014\n",
      "Epoch 830/1200\n",
      "1137/1137 [==============================] - 1s 558us/step - loss: 16466.7628 - val_loss: 29857.2654\n",
      "Epoch 831/1200\n",
      "1137/1137 [==============================] - 1s 600us/step - loss: 16416.1366 - val_loss: 28303.4837\n",
      "Epoch 832/1200\n",
      "1137/1137 [==============================] - 1s 543us/step - loss: 17243.2770 - val_loss: 29672.2422\n",
      "Epoch 833/1200\n",
      "1137/1137 [==============================] - 1s 545us/step - loss: 17049.5172 - val_loss: 28432.0015\n",
      "Epoch 834/1200\n",
      "1137/1137 [==============================] - 1s 528us/step - loss: 16690.7791 - val_loss: 27622.2669\n",
      "Epoch 835/1200\n",
      "1137/1137 [==============================] - 1s 550us/step - loss: 16051.1021 - val_loss: 28174.3593\n",
      "Epoch 836/1200\n",
      "1137/1137 [==============================] - 1s 584us/step - loss: 16681.0132 - val_loss: 27669.9852\n",
      "Epoch 837/1200\n",
      "1137/1137 [==============================] - 1s 598us/step - loss: 17082.8299 - val_loss: 29305.4333\n",
      "Epoch 838/1200\n",
      "1137/1137 [==============================] - 1s 553us/step - loss: 16790.5765 - val_loss: 27982.5223\n",
      "Epoch 839/1200\n",
      "1137/1137 [==============================] - 1s 546us/step - loss: 16920.9554 - val_loss: 29731.3636\n",
      "Epoch 840/1200\n",
      "1137/1137 [==============================] - 1s 543us/step - loss: 16490.0170 - val_loss: 27319.5187\n",
      "Epoch 841/1200\n",
      "1137/1137 [==============================] - 1s 553us/step - loss: 16572.2156 - val_loss: 27349.1431\n",
      "Epoch 842/1200\n",
      "1137/1137 [==============================] - 1s 561us/step - loss: 18308.0091 - val_loss: 28790.8398\n",
      "Epoch 843/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 16272.2361 - val_loss: 28001.8682\n",
      "Epoch 844/1200\n",
      "1137/1137 [==============================] - 1s 547us/step - loss: 17103.8409 - val_loss: 27466.9082\n",
      "Epoch 845/1200\n",
      "1137/1137 [==============================] - 1s 549us/step - loss: 16284.6930 - val_loss: 28036.6985\n",
      "Epoch 846/1200\n",
      "1137/1137 [==============================] - 1s 542us/step - loss: 17385.7795 - val_loss: 28228.2819\n",
      "Epoch 847/1200\n",
      "1137/1137 [==============================] - 1s 556us/step - loss: 17087.9718 - val_loss: 29028.6320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 848/1200\n",
      "1137/1137 [==============================] - 1s 567us/step - loss: 16508.3402 - val_loss: 27713.4826\n",
      "Epoch 849/1200\n",
      "1137/1137 [==============================] - 1s 533us/step - loss: 16217.4063 - val_loss: 27256.7165\n",
      "Epoch 850/1200\n",
      "1137/1137 [==============================] - 1s 518us/step - loss: 16995.8155 - val_loss: 27780.1186\n",
      "Epoch 851/1200\n",
      "1137/1137 [==============================] - 1s 540us/step - loss: 16746.2463 - val_loss: 27890.3531\n",
      "Epoch 852/1200\n",
      "1137/1137 [==============================] - 1s 535us/step - loss: 17289.6047 - val_loss: 27861.4362\n",
      "Epoch 853/1200\n",
      "1137/1137 [==============================] - 1s 532us/step - loss: 16596.8447 - val_loss: 28544.0446\n",
      "Epoch 854/1200\n",
      "1137/1137 [==============================] - 1s 541us/step - loss: 16458.5179 - val_loss: 26950.4179\n",
      "Epoch 855/1200\n",
      "1137/1137 [==============================] - 1s 547us/step - loss: 16762.6416 - val_loss: 28450.3703\n",
      "Epoch 856/1200\n",
      "1137/1137 [==============================] - 1s 517us/step - loss: 16623.6659 - val_loss: 28568.8821\n",
      "Epoch 857/1200\n",
      "1137/1137 [==============================] - 1s 580us/step - loss: 16325.9601 - val_loss: 28916.2111\n",
      "Epoch 858/1200\n",
      "1137/1137 [==============================] - 1s 591us/step - loss: 16564.5325 - val_loss: 28548.4618\n",
      "Epoch 859/1200\n",
      "1137/1137 [==============================] - 1s 564us/step - loss: 15989.5085 - val_loss: 30250.6534\n",
      "Epoch 860/1200\n",
      "1137/1137 [==============================] - 1s 601us/step - loss: 16513.9833 - val_loss: 27155.1222\n",
      "Epoch 861/1200\n",
      "1137/1137 [==============================] - 1s 534us/step - loss: 16161.7171 - val_loss: 28112.6269\n",
      "Epoch 862/1200\n",
      "1137/1137 [==============================] - 1s 583us/step - loss: 16698.1713 - val_loss: 30448.2121\n",
      "Epoch 863/1200\n",
      "1137/1137 [==============================] - 1s 557us/step - loss: 16903.5469 - val_loss: 28503.5058\n",
      "Epoch 864/1200\n",
      "1137/1137 [==============================] - 1s 538us/step - loss: 16805.8977 - val_loss: 32034.5581\n",
      "Epoch 865/1200\n",
      "1137/1137 [==============================] - 1s 575us/step - loss: 16839.1123 - val_loss: 28286.2516\n",
      "Epoch 866/1200\n",
      "1137/1137 [==============================] - 1s 544us/step - loss: 16745.9520 - val_loss: 34459.5634\n",
      "Epoch 867/1200\n",
      "1137/1137 [==============================] - 1s 538us/step - loss: 16986.3303 - val_loss: 29030.3098\n",
      "Epoch 868/1200\n",
      "1137/1137 [==============================] - 1s 545us/step - loss: 16360.0245 - val_loss: 27900.6905\n",
      "Epoch 869/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 15961.0441 - val_loss: 27576.0009\n",
      "Epoch 870/1200\n",
      "1137/1137 [==============================] - 1s 587us/step - loss: 16701.0870 - val_loss: 27823.1508\n",
      "Epoch 871/1200\n",
      "1137/1137 [==============================] - 1s 540us/step - loss: 16120.5878 - val_loss: 27814.7040\n",
      "Epoch 872/1200\n",
      "1137/1137 [==============================] - 1s 565us/step - loss: 16539.7064 - val_loss: 28082.2757\n",
      "Epoch 873/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 16245.6741 - val_loss: 26819.3938\n",
      "Epoch 874/1200\n",
      "1137/1137 [==============================] - 1s 535us/step - loss: 16182.3920 - val_loss: 27531.1503\n",
      "Epoch 875/1200\n",
      "1137/1137 [==============================] - 1s 528us/step - loss: 16613.8755 - val_loss: 27703.8468\n",
      "Epoch 876/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 16082.8112 - val_loss: 30859.5701\n",
      "Epoch 877/1200\n",
      "1137/1137 [==============================] - 1s 575us/step - loss: 15615.6292 - val_loss: 28592.1837\n",
      "Epoch 878/1200\n",
      "1137/1137 [==============================] - 1s 574us/step - loss: 16572.5140 - val_loss: 32590.4728\n",
      "Epoch 879/1200\n",
      "1137/1137 [==============================] - 1s 532us/step - loss: 16019.9281 - val_loss: 28606.2231\n",
      "Epoch 880/1200\n",
      "1137/1137 [==============================] - 1s 543us/step - loss: 16449.6123 - val_loss: 28039.8665\n",
      "Epoch 881/1200\n",
      "1137/1137 [==============================] - 1s 548us/step - loss: 16996.2158 - val_loss: 27069.2836\n",
      "Epoch 882/1200\n",
      "1137/1137 [==============================] - 1s 563us/step - loss: 16185.6356 - val_loss: 29130.4642\n",
      "Epoch 883/1200\n",
      "1137/1137 [==============================] - 1s 569us/step - loss: 16462.8286 - val_loss: 26740.1149\n",
      "Epoch 884/1200\n",
      "1137/1137 [==============================] - 1s 545us/step - loss: 16211.0202 - val_loss: 27884.3369\n",
      "Epoch 885/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 16468.0193 - val_loss: 27838.6969\n",
      "Epoch 886/1200\n",
      "1137/1137 [==============================] - 1s 562us/step - loss: 17066.6919 - val_loss: 27292.8655\n",
      "Epoch 887/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 15901.7073 - val_loss: 27750.6701\n",
      "Epoch 888/1200\n",
      "1137/1137 [==============================] - 1s 534us/step - loss: 15840.3408 - val_loss: 26968.6637\n",
      "Epoch 889/1200\n",
      "1137/1137 [==============================] - 1s 527us/step - loss: 17038.0024 - val_loss: 27061.0874\n",
      "Epoch 890/1200\n",
      "1137/1137 [==============================] - 1s 583us/step - loss: 15924.6527 - val_loss: 27739.8884\n",
      "Epoch 891/1200\n",
      "1137/1137 [==============================] - 1s 546us/step - loss: 16067.0231 - val_loss: 27515.9894\n",
      "Epoch 892/1200\n",
      "1137/1137 [==============================] - 1s 536us/step - loss: 15914.5463 - val_loss: 27361.3949\n",
      "Epoch 893/1200\n",
      "1137/1137 [==============================] - 1s 568us/step - loss: 15668.5788 - val_loss: 26907.3161\n",
      "Epoch 894/1200\n",
      "1137/1137 [==============================] - 1s 593us/step - loss: 15738.7408 - val_loss: 27281.5911\n",
      "Epoch 895/1200\n",
      "1137/1137 [==============================] - 1s 529us/step - loss: 16236.7964 - val_loss: 28197.1196\n",
      "Epoch 896/1200\n",
      "1137/1137 [==============================] - 1s 536us/step - loss: 16936.4345 - val_loss: 30714.8281\n",
      "Epoch 897/1200\n",
      "1137/1137 [==============================] - 1s 583us/step - loss: 16973.3600 - val_loss: 27133.4863\n",
      "Epoch 898/1200\n",
      "1137/1137 [==============================] - 1s 561us/step - loss: 16077.6408 - val_loss: 28007.3622\n",
      "Epoch 899/1200\n",
      "1137/1137 [==============================] - 1s 544us/step - loss: 15746.3677 - val_loss: 28060.0100\n",
      "Epoch 900/1200\n",
      "1137/1137 [==============================] - 1s 585us/step - loss: 16500.9550 - val_loss: 27212.3788\n",
      "Epoch 901/1200\n",
      "1137/1137 [==============================] - 1s 543us/step - loss: 16089.4526 - val_loss: 26995.4556\n",
      "Epoch 902/1200\n",
      "1137/1137 [==============================] - 1s 535us/step - loss: 16346.2880 - val_loss: 28095.5740\n",
      "Epoch 903/1200\n",
      "1137/1137 [==============================] - 1s 543us/step - loss: 16020.7601 - val_loss: 28012.6627\n",
      "Epoch 904/1200\n",
      "1137/1137 [==============================] - 1s 586us/step - loss: 15890.7636 - val_loss: 27249.2637\n",
      "Epoch 905/1200\n",
      "1137/1137 [==============================] - 1s 596us/step - loss: 16492.4562 - val_loss: 29905.8495\n",
      "Epoch 906/1200\n",
      "1137/1137 [==============================] - 1s 604us/step - loss: 16336.0152 - val_loss: 27014.4470\n",
      "Epoch 907/1200\n",
      "1137/1137 [==============================] - 1s 547us/step - loss: 15879.0667 - val_loss: 26558.7539\n",
      "Epoch 908/1200\n",
      "1137/1137 [==============================] - 1s 573us/step - loss: 15666.7439 - val_loss: 27544.3838\n",
      "Epoch 909/1200\n",
      "1137/1137 [==============================] - 1s 542us/step - loss: 15668.7783 - val_loss: 27280.7605\n",
      "Epoch 910/1200\n",
      "1137/1137 [==============================] - 1s 529us/step - loss: 16282.7481 - val_loss: 27599.6628\n",
      "Epoch 911/1200\n",
      "1137/1137 [==============================] - 1s 573us/step - loss: 15400.0583 - val_loss: 28199.9042\n",
      "Epoch 912/1200\n",
      "1137/1137 [==============================] - 1s 586us/step - loss: 15644.0328 - val_loss: 27392.9712\n",
      "Epoch 913/1200\n",
      "1137/1137 [==============================] - 1s 578us/step - loss: 15865.1866 - val_loss: 27179.5219\n",
      "Epoch 914/1200\n",
      "1137/1137 [==============================] - 1s 549us/step - loss: 16075.1726 - val_loss: 27126.0155\n",
      "Epoch 915/1200\n",
      "1137/1137 [==============================] - 1s 596us/step - loss: 16201.3643 - val_loss: 27810.1774\n",
      "Epoch 916/1200\n",
      "1137/1137 [==============================] - 1s 552us/step - loss: 15515.4947 - val_loss: 26630.3335\n",
      "Epoch 917/1200\n",
      "1137/1137 [==============================] - 1s 603us/step - loss: 15576.9470 - val_loss: 26938.9510\n",
      "Epoch 918/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 1s 578us/step - loss: 16120.9470 - val_loss: 26841.3479\n",
      "Epoch 919/1200\n",
      "1137/1137 [==============================] - 1s 532us/step - loss: 15409.6200 - val_loss: 26600.8377\n",
      "Epoch 920/1200\n",
      "1137/1137 [==============================] - 1s 552us/step - loss: 15536.9878 - val_loss: 27031.0971\n",
      "Epoch 921/1200\n",
      "1137/1137 [==============================] - 1s 538us/step - loss: 16011.4863 - val_loss: 29336.5913\n",
      "Epoch 922/1200\n",
      "1137/1137 [==============================] - 1s 558us/step - loss: 15911.5677 - val_loss: 29376.7270\n",
      "Epoch 923/1200\n",
      "1137/1137 [==============================] - 1s 560us/step - loss: 16580.3319 - val_loss: 26865.1589\n",
      "Epoch 924/1200\n",
      "1137/1137 [==============================] - 1s 504us/step - loss: 15639.3716 - val_loss: 27400.9302\n",
      "Epoch 925/1200\n",
      "1137/1137 [==============================] - 1s 547us/step - loss: 16811.4355 - val_loss: 27105.7484\n",
      "Epoch 926/1200\n",
      "1137/1137 [==============================] - 1s 594us/step - loss: 16027.9377 - val_loss: 27869.7242\n",
      "Epoch 927/1200\n",
      "1137/1137 [==============================] - 1s 580us/step - loss: 15439.7291 - val_loss: 26580.1438\n",
      "Epoch 928/1200\n",
      "1137/1137 [==============================] - 1s 559us/step - loss: 16699.4572 - val_loss: 27115.9466\n",
      "Epoch 929/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 16670.2940 - val_loss: 28449.1738\n",
      "Epoch 930/1200\n",
      "1137/1137 [==============================] - 1s 579us/step - loss: 15849.6631 - val_loss: 28596.3985\n",
      "Epoch 931/1200\n",
      "1137/1137 [==============================] - 1s 561us/step - loss: 16316.9829 - val_loss: 27880.7116\n",
      "Epoch 932/1200\n",
      "1137/1137 [==============================] - 1s 560us/step - loss: 15679.0169 - val_loss: 27565.1209\n",
      "Epoch 933/1200\n",
      "1137/1137 [==============================] - 1s 594us/step - loss: 16482.4942 - val_loss: 26756.6128\n",
      "Epoch 934/1200\n",
      "1137/1137 [==============================] - 1s 577us/step - loss: 16325.8409 - val_loss: 27585.2243\n",
      "Epoch 935/1200\n",
      "1137/1137 [==============================] - 1s 552us/step - loss: 15792.1129 - val_loss: 28549.5811\n",
      "Epoch 936/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 16726.9120 - val_loss: 27042.0578\n",
      "Epoch 937/1200\n",
      "1137/1137 [==============================] - 1s 582us/step - loss: 15671.6488 - val_loss: 27330.3150\n",
      "Epoch 938/1200\n",
      "1137/1137 [==============================] - 1s 549us/step - loss: 15962.7683 - val_loss: 28403.5980\n",
      "Epoch 939/1200\n",
      "1137/1137 [==============================] - 1s 580us/step - loss: 15737.6162 - val_loss: 26868.7240\n",
      "Epoch 940/1200\n",
      "1137/1137 [==============================] - 1s 575us/step - loss: 15292.4691 - val_loss: 26818.0544\n",
      "Epoch 941/1200\n",
      "1137/1137 [==============================] - 1s 580us/step - loss: 16015.8629 - val_loss: 26718.2187\n",
      "Epoch 942/1200\n",
      "1137/1137 [==============================] - 1s 550us/step - loss: 16060.8823 - val_loss: 29808.9287\n",
      "Epoch 943/1200\n",
      "1137/1137 [==============================] - 1s 576us/step - loss: 16206.5198 - val_loss: 26628.4667\n",
      "Epoch 944/1200\n",
      "1137/1137 [==============================] - 1s 580us/step - loss: 15193.0576 - val_loss: 27902.2153\n",
      "Epoch 945/1200\n",
      "1137/1137 [==============================] - 1s 616us/step - loss: 15633.8432 - val_loss: 26328.8120\n",
      "Epoch 946/1200\n",
      "1137/1137 [==============================] - 1s 603us/step - loss: 15675.3313 - val_loss: 28103.3062\n",
      "Epoch 947/1200\n",
      "1137/1137 [==============================] - 1s 638us/step - loss: 16115.7138 - val_loss: 26866.7516\n",
      "Epoch 948/1200\n",
      "1137/1137 [==============================] - 1s 604us/step - loss: 16154.7316 - val_loss: 26531.1433\n",
      "Epoch 949/1200\n",
      "1137/1137 [==============================] - 1s 590us/step - loss: 15832.2692 - val_loss: 27090.5698\n",
      "Epoch 950/1200\n",
      "1137/1137 [==============================] - 1s 594us/step - loss: 16133.2709 - val_loss: 28549.1152\n",
      "Epoch 951/1200\n",
      "1137/1137 [==============================] - 1s 595us/step - loss: 15544.8761 - val_loss: 27947.8865\n",
      "Epoch 952/1200\n",
      "1137/1137 [==============================] - 1s 594us/step - loss: 15968.6370 - val_loss: 26552.9539\n",
      "Epoch 953/1200\n",
      "1137/1137 [==============================] - 1s 585us/step - loss: 16332.1050 - val_loss: 27003.4407\n",
      "Epoch 954/1200\n",
      "1137/1137 [==============================] - 1s 594us/step - loss: 15541.1719 - val_loss: 26592.8396\n",
      "Epoch 955/1200\n",
      "1137/1137 [==============================] - 1s 596us/step - loss: 15723.2674 - val_loss: 27402.8684\n",
      "Epoch 956/1200\n",
      "1137/1137 [==============================] - 1s 585us/step - loss: 15789.5688 - val_loss: 26555.7173\n",
      "Epoch 957/1200\n",
      "1137/1137 [==============================] - 1s 536us/step - loss: 16398.4633 - val_loss: 26716.5861\n",
      "Epoch 958/1200\n",
      "1137/1137 [==============================] - 1s 545us/step - loss: 15402.5825 - val_loss: 26910.9687\n",
      "Epoch 959/1200\n",
      "1137/1137 [==============================] - 1s 576us/step - loss: 16277.2546 - val_loss: 26786.0621\n",
      "Epoch 960/1200\n",
      "1137/1137 [==============================] - 1s 567us/step - loss: 15914.9808 - val_loss: 29512.0045\n",
      "Epoch 961/1200\n",
      "1137/1137 [==============================] - 1s 589us/step - loss: 15802.2933 - val_loss: 26662.6360\n",
      "Epoch 962/1200\n",
      "1137/1137 [==============================] - 1s 548us/step - loss: 15527.6145 - val_loss: 27403.8563\n",
      "Epoch 963/1200\n",
      "1137/1137 [==============================] - 1s 562us/step - loss: 15771.9037 - val_loss: 26246.4240\n",
      "Epoch 964/1200\n",
      "1137/1137 [==============================] - 1s 542us/step - loss: 16173.5875 - val_loss: 28788.2725\n",
      "Epoch 965/1200\n",
      "1137/1137 [==============================] - 1s 528us/step - loss: 14856.7700 - val_loss: 27934.6447\n",
      "Epoch 966/1200\n",
      "1137/1137 [==============================] - 1s 544us/step - loss: 15867.6798 - val_loss: 25722.4019\n",
      "Epoch 967/1200\n",
      "1137/1137 [==============================] - 1s 588us/step - loss: 15585.3854 - val_loss: 26167.0738\n",
      "Epoch 968/1200\n",
      "1137/1137 [==============================] - 1s 583us/step - loss: 16162.6796 - val_loss: 26314.2476\n",
      "Epoch 969/1200\n",
      "1137/1137 [==============================] - 1s 548us/step - loss: 14978.0601 - val_loss: 29175.6669\n",
      "Epoch 970/1200\n",
      "1137/1137 [==============================] - 1s 605us/step - loss: 15416.0276 - val_loss: 26309.5517\n",
      "Epoch 971/1200\n",
      "1137/1137 [==============================] - 1s 596us/step - loss: 16062.7015 - val_loss: 29539.6939\n",
      "Epoch 972/1200\n",
      "1137/1137 [==============================] - 1s 591us/step - loss: 16033.6396 - val_loss: 28761.2639\n",
      "Epoch 973/1200\n",
      "1137/1137 [==============================] - 1s 590us/step - loss: 15462.4871 - val_loss: 27032.4031\n",
      "Epoch 974/1200\n",
      "1137/1137 [==============================] - 1s 586us/step - loss: 16274.7323 - val_loss: 25838.2315\n",
      "Epoch 975/1200\n",
      "1137/1137 [==============================] - 1s 597us/step - loss: 15368.2539 - val_loss: 25957.2412\n",
      "Epoch 976/1200\n",
      "1137/1137 [==============================] - 1s 599us/step - loss: 15235.5572 - val_loss: 26486.9419\n",
      "Epoch 977/1200\n",
      "1137/1137 [==============================] - 1s 542us/step - loss: 15308.2048 - val_loss: 26416.1767\n",
      "Epoch 978/1200\n",
      "1137/1137 [==============================] - 1s 585us/step - loss: 14969.7567 - val_loss: 26418.6471\n",
      "Epoch 979/1200\n",
      "1137/1137 [==============================] - 1s 597us/step - loss: 15123.7811 - val_loss: 26611.3661\n",
      "Epoch 980/1200\n",
      "1137/1137 [==============================] - 1s 548us/step - loss: 15286.9555 - val_loss: 32509.3360\n",
      "Epoch 981/1200\n",
      "1137/1137 [==============================] - 1s 567us/step - loss: 16397.0694 - val_loss: 26117.5055\n",
      "Epoch 982/1200\n",
      "1137/1137 [==============================] - 1s 600us/step - loss: 15346.7979 - val_loss: 26128.6328\n",
      "Epoch 983/1200\n",
      "1137/1137 [==============================] - 1s 594us/step - loss: 15291.5485 - val_loss: 26176.8931\n",
      "Epoch 984/1200\n",
      "1137/1137 [==============================] - 1s 547us/step - loss: 15388.8462 - val_loss: 27889.8876\n",
      "Epoch 985/1200\n",
      "1137/1137 [==============================] - 1s 565us/step - loss: 15364.7969 - val_loss: 27122.9338\n",
      "Epoch 986/1200\n",
      "1137/1137 [==============================] - 1s 545us/step - loss: 16020.3360 - val_loss: 28545.2440\n",
      "Epoch 987/1200\n",
      "1137/1137 [==============================] - 1s 588us/step - loss: 15525.8949 - val_loss: 27742.6821\n",
      "Epoch 988/1200\n",
      "1137/1137 [==============================] - 1s 567us/step - loss: 15428.8892 - val_loss: 26845.0851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 989/1200\n",
      "1137/1137 [==============================] - 1s 589us/step - loss: 15274.6309 - val_loss: 26140.5189\n",
      "Epoch 990/1200\n",
      "1137/1137 [==============================] - 1s 576us/step - loss: 15476.9228 - val_loss: 26590.9805\n",
      "Epoch 991/1200\n",
      "1137/1137 [==============================] - 1s 568us/step - loss: 15158.2377 - val_loss: 27935.2328\n",
      "Epoch 992/1200\n",
      "1137/1137 [==============================] - 1s 555us/step - loss: 15437.2853 - val_loss: 26930.3214\n",
      "Epoch 993/1200\n",
      "1137/1137 [==============================] - 1s 565us/step - loss: 15414.6612 - val_loss: 26040.8350\n",
      "Epoch 994/1200\n",
      "1137/1137 [==============================] - 1s 536us/step - loss: 16275.9343 - val_loss: 27122.6482\n",
      "Epoch 995/1200\n",
      "1137/1137 [==============================] - 1s 548us/step - loss: 15341.6532 - val_loss: 25970.2121\n",
      "Epoch 996/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 15648.3088 - val_loss: 27575.5363\n",
      "Epoch 997/1200\n",
      "1137/1137 [==============================] - 1s 536us/step - loss: 15969.6647 - val_loss: 26725.7046\n",
      "Epoch 998/1200\n",
      "1137/1137 [==============================] - 1s 524us/step - loss: 15325.1932 - val_loss: 26813.4853\n",
      "Epoch 999/1200\n",
      "1137/1137 [==============================] - 1s 547us/step - loss: 15430.4913 - val_loss: 29047.3311\n",
      "Epoch 1000/1200\n",
      "1137/1137 [==============================] - 1s 593us/step - loss: 15921.6102 - val_loss: 25782.7632\n",
      "Epoch 1001/1200\n",
      "1137/1137 [==============================] - 1s 545us/step - loss: 15293.8941 - val_loss: 27059.4371\n",
      "Epoch 1002/1200\n",
      "1137/1137 [==============================] - 1s 545us/step - loss: 15631.6463 - val_loss: 25956.5548\n",
      "Epoch 1003/1200\n",
      "1137/1137 [==============================] - 1s 548us/step - loss: 16022.1155 - val_loss: 26717.2403\n",
      "Epoch 1004/1200\n",
      "1137/1137 [==============================] - 1s 522us/step - loss: 15317.1901 - val_loss: 27993.7021\n",
      "Epoch 1005/1200\n",
      "1137/1137 [==============================] - 1s 532us/step - loss: 15965.7287 - val_loss: 26023.7076\n",
      "Epoch 1006/1200\n",
      "1137/1137 [==============================] - 1s 524us/step - loss: 15853.5925 - val_loss: 28664.5898\n",
      "Epoch 1007/1200\n",
      "1137/1137 [==============================] - 1s 536us/step - loss: 16336.3373 - val_loss: 25810.7456\n",
      "Epoch 1008/1200\n",
      "1137/1137 [==============================] - 1s 524us/step - loss: 14987.4495 - val_loss: 26281.9038\n",
      "Epoch 1009/1200\n",
      "1137/1137 [==============================] - 1s 541us/step - loss: 15034.9432 - val_loss: 26060.6056\n",
      "Epoch 1010/1200\n",
      "1137/1137 [==============================] - 1s 576us/step - loss: 15096.4879 - val_loss: 27212.7516\n",
      "Epoch 1011/1200\n",
      "1137/1137 [==============================] - 1s 532us/step - loss: 15252.6005 - val_loss: 27018.8520\n",
      "Epoch 1012/1200\n",
      "1137/1137 [==============================] - 1s 552us/step - loss: 15363.4269 - val_loss: 26225.1349\n",
      "Epoch 1013/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 15123.3244 - val_loss: 27596.4362\n",
      "Epoch 1014/1200\n",
      "1137/1137 [==============================] - 1s 535us/step - loss: 15196.9129 - val_loss: 26527.4280\n",
      "Epoch 1015/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 14976.4158 - val_loss: 27416.4175\n",
      "Epoch 1016/1200\n",
      "1137/1137 [==============================] - 1s 540us/step - loss: 15151.7687 - val_loss: 26439.0056\n",
      "Epoch 1017/1200\n",
      "1137/1137 [==============================] - 1s 525us/step - loss: 16074.2359 - val_loss: 26195.7970\n",
      "Epoch 1018/1200\n",
      "1137/1137 [==============================] - 1s 586us/step - loss: 14581.9411 - val_loss: 26164.4209\n",
      "Epoch 1019/1200\n",
      "1137/1137 [==============================] - 1s 526us/step - loss: 14650.0475 - val_loss: 26105.4680\n",
      "Epoch 1020/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 15233.4494 - val_loss: 26739.0937\n",
      "Epoch 1021/1200\n",
      "1137/1137 [==============================] - 1s 581us/step - loss: 15567.6972 - val_loss: 29570.2389\n",
      "Epoch 1022/1200\n",
      "1137/1137 [==============================] - 1s 553us/step - loss: 14677.8302 - val_loss: 25838.1946\n",
      "Epoch 1023/1200\n",
      "1137/1137 [==============================] - 1s 593us/step - loss: 15135.1744 - val_loss: 25921.7609\n",
      "Epoch 1024/1200\n",
      "1137/1137 [==============================] - 1s 596us/step - loss: 15295.6451 - val_loss: 29412.5543\n",
      "Epoch 1025/1200\n",
      "1137/1137 [==============================] - 1s 589us/step - loss: 16552.1759 - val_loss: 26048.0322\n",
      "Epoch 1026/1200\n",
      "1137/1137 [==============================] - 1s 576us/step - loss: 15326.6460 - val_loss: 26712.8580\n",
      "Epoch 1027/1200\n",
      "1137/1137 [==============================] - 1s 601us/step - loss: 15226.5730 - val_loss: 26478.3503\n",
      "Epoch 1028/1200\n",
      "1137/1137 [==============================] - 1s 588us/step - loss: 15212.9185 - val_loss: 26168.7342\n",
      "Epoch 1029/1200\n",
      "1137/1137 [==============================] - 1s 593us/step - loss: 15066.4061 - val_loss: 26348.7150\n",
      "Epoch 1030/1200\n",
      "1137/1137 [==============================] - 1s 585us/step - loss: 15873.4303 - val_loss: 26129.2813\n",
      "Epoch 1031/1200\n",
      "1137/1137 [==============================] - 1s 582us/step - loss: 16393.0080 - val_loss: 26097.2436\n",
      "Epoch 1032/1200\n",
      "1137/1137 [==============================] - 1s 554us/step - loss: 15448.6235 - val_loss: 25811.0815\n",
      "Epoch 1033/1200\n",
      "1137/1137 [==============================] - 1s 575us/step - loss: 15468.4074 - val_loss: 28002.7702\n",
      "Epoch 1034/1200\n",
      "1137/1137 [==============================] - 1s 578us/step - loss: 14976.8522 - val_loss: 26941.8504\n",
      "Epoch 1035/1200\n",
      "1137/1137 [==============================] - 1s 552us/step - loss: 15686.8191 - val_loss: 27105.2162\n",
      "Epoch 1036/1200\n",
      "1137/1137 [==============================] - 1s 586us/step - loss: 15725.1239 - val_loss: 27832.3833\n",
      "Epoch 1037/1200\n",
      "1137/1137 [==============================] - 1s 591us/step - loss: 15454.3316 - val_loss: 26143.2027\n",
      "Epoch 1038/1200\n",
      "1137/1137 [==============================] - 1s 542us/step - loss: 15338.9648 - val_loss: 25813.2954\n",
      "Epoch 1039/1200\n",
      "1137/1137 [==============================] - 1s 536us/step - loss: 14924.1608 - val_loss: 26163.8634\n",
      "Epoch 1040/1200\n",
      "1137/1137 [==============================] - 1s 574us/step - loss: 14767.7779 - val_loss: 27316.4413\n",
      "Epoch 1041/1200\n",
      "1137/1137 [==============================] - 1s 524us/step - loss: 15517.7197 - val_loss: 26290.4557\n",
      "Epoch 1042/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 15217.5984 - val_loss: 25630.6065\n",
      "Epoch 1043/1200\n",
      "1137/1137 [==============================] - 1s 545us/step - loss: 15576.8027 - val_loss: 26002.0967\n",
      "Epoch 1044/1200\n",
      "1137/1137 [==============================] - 1s 593us/step - loss: 15406.9012 - val_loss: 26404.0497\n",
      "Epoch 1045/1200\n",
      "1137/1137 [==============================] - 1s 518us/step - loss: 14732.5302 - val_loss: 26449.5216\n",
      "Epoch 1046/1200\n",
      "1137/1137 [==============================] - 1s 571us/step - loss: 15298.5937 - val_loss: 26578.3821\n",
      "Epoch 1047/1200\n",
      "1137/1137 [==============================] - 1s 570us/step - loss: 15507.9423 - val_loss: 26222.1618\n",
      "Epoch 1048/1200\n",
      "1137/1137 [==============================] - 1s 535us/step - loss: 15378.2768 - val_loss: 26301.7644\n",
      "Epoch 1049/1200\n",
      "1137/1137 [==============================] - 1s 578us/step - loss: 15074.7498 - val_loss: 26129.0286\n",
      "Epoch 1050/1200\n",
      "1137/1137 [==============================] - 1s 545us/step - loss: 15342.0108 - val_loss: 26945.6233\n",
      "Epoch 1051/1200\n",
      "1137/1137 [==============================] - 1s 536us/step - loss: 15420.1764 - val_loss: 26390.6484\n",
      "Epoch 1052/1200\n",
      "1137/1137 [==============================] - 1s 543us/step - loss: 15078.7484 - val_loss: 26291.5992\n",
      "Epoch 1053/1200\n",
      "1137/1137 [==============================] - 1s 546us/step - loss: 14109.3851 - val_loss: 25543.0309\n",
      "Epoch 1054/1200\n",
      "1137/1137 [==============================] - 1s 561us/step - loss: 14587.7065 - val_loss: 25916.9641\n",
      "Epoch 1055/1200\n",
      "1137/1137 [==============================] - 1s 545us/step - loss: 14853.4381 - val_loss: 25499.2476\n",
      "Epoch 1056/1200\n",
      "1137/1137 [==============================] - 1s 542us/step - loss: 14497.6583 - val_loss: 26791.4296\n",
      "Epoch 1057/1200\n",
      "1137/1137 [==============================] - 1s 551us/step - loss: 14853.6108 - val_loss: 28203.1919\n",
      "Epoch 1058/1200\n",
      "1137/1137 [==============================] - 1s 524us/step - loss: 15389.0934 - val_loss: 25825.3314\n",
      "Epoch 1059/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 1s 589us/step - loss: 14871.0911 - val_loss: 26356.4520\n",
      "Epoch 1060/1200\n",
      "1137/1137 [==============================] - 1s 587us/step - loss: 14496.4978 - val_loss: 26632.3966\n",
      "Epoch 1061/1200\n",
      "1137/1137 [==============================] - 1s 589us/step - loss: 15269.7114 - val_loss: 26428.1748\n",
      "Epoch 1062/1200\n",
      "1137/1137 [==============================] - 1s 552us/step - loss: 14945.7923 - val_loss: 26453.2520\n",
      "Epoch 1063/1200\n",
      "1137/1137 [==============================] - 1s 579us/step - loss: 14941.7480 - val_loss: 25890.6027\n",
      "Epoch 1064/1200\n",
      "1137/1137 [==============================] - 1s 582us/step - loss: 15389.1332 - val_loss: 28080.7367\n",
      "Epoch 1065/1200\n",
      "1137/1137 [==============================] - 1s 532us/step - loss: 14643.0492 - val_loss: 26478.0723\n",
      "Epoch 1066/1200\n",
      "1137/1137 [==============================] - 1s 521us/step - loss: 15031.4529 - val_loss: 25780.6788\n",
      "Epoch 1067/1200\n",
      "1137/1137 [==============================] - 1s 564us/step - loss: 14850.7558 - val_loss: 26214.8576\n",
      "Epoch 1068/1200\n",
      "1137/1137 [==============================] - 1s 532us/step - loss: 14735.8165 - val_loss: 25844.7483\n",
      "Epoch 1069/1200\n",
      "1137/1137 [==============================] - 1s 525us/step - loss: 15135.5989 - val_loss: 26836.2288\n",
      "Epoch 1070/1200\n",
      "1137/1137 [==============================] - 1s 527us/step - loss: 15831.8409 - val_loss: 26362.6621\n",
      "Epoch 1071/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 15421.2524 - val_loss: 26870.5121\n",
      "Epoch 1072/1200\n",
      "1137/1137 [==============================] - 1s 549us/step - loss: 15153.6389 - val_loss: 26004.2462\n",
      "Epoch 1073/1200\n",
      "1137/1137 [==============================] - 1s 562us/step - loss: 14870.0819 - val_loss: 26182.8131\n",
      "Epoch 1074/1200\n",
      "1137/1137 [==============================] - 1s 589us/step - loss: 14567.8216 - val_loss: 27357.5978\n",
      "Epoch 1075/1200\n",
      "1137/1137 [==============================] - 1s 590us/step - loss: 15508.1684 - val_loss: 26043.0520\n",
      "Epoch 1076/1200\n",
      "1137/1137 [==============================] - 1s 564us/step - loss: 14922.2779 - val_loss: 29087.3194\n",
      "Epoch 1077/1200\n",
      "1137/1137 [==============================] - 1s 558us/step - loss: 14821.0140 - val_loss: 25579.9662\n",
      "Epoch 1078/1200\n",
      "1137/1137 [==============================] - 1s 585us/step - loss: 15259.5175 - val_loss: 27266.7276\n",
      "Epoch 1079/1200\n",
      "1137/1137 [==============================] - 1s 597us/step - loss: 15256.4539 - val_loss: 26317.2993\n",
      "Epoch 1080/1200\n",
      "1137/1137 [==============================] - 1s 566us/step - loss: 14209.3620 - val_loss: 26220.5782\n",
      "Epoch 1081/1200\n",
      "1137/1137 [==============================] - 1s 532us/step - loss: 15022.2047 - val_loss: 25973.0343\n",
      "Epoch 1082/1200\n",
      "1137/1137 [==============================] - 1s 525us/step - loss: 14491.4531 - val_loss: 27191.4679\n",
      "Epoch 1083/1200\n",
      "1137/1137 [==============================] - 1s 562us/step - loss: 14576.6713 - val_loss: 25998.3863\n",
      "Epoch 1084/1200\n",
      "1137/1137 [==============================] - 1s 563us/step - loss: 14567.5943 - val_loss: 26989.0792\n",
      "Epoch 1085/1200\n",
      "1137/1137 [==============================] - 1s 596us/step - loss: 14326.7023 - val_loss: 27551.9441\n",
      "Epoch 1086/1200\n",
      "1137/1137 [==============================] - 1s 596us/step - loss: 14631.0116 - val_loss: 27440.9344\n",
      "Epoch 1087/1200\n",
      "1137/1137 [==============================] - 1s 589us/step - loss: 14624.6193 - val_loss: 25797.6783\n",
      "Epoch 1088/1200\n",
      "1137/1137 [==============================] - 1s 596us/step - loss: 14409.6049 - val_loss: 26895.7088\n",
      "Epoch 1089/1200\n",
      "1137/1137 [==============================] - 1s 546us/step - loss: 14403.0867 - val_loss: 27331.3944\n",
      "Epoch 1090/1200\n",
      "1137/1137 [==============================] - 1s 568us/step - loss: 15466.7743 - val_loss: 25821.0944\n",
      "Epoch 1091/1200\n",
      "1137/1137 [==============================] - 1s 585us/step - loss: 14487.2188 - val_loss: 25833.2278\n",
      "Epoch 1092/1200\n",
      "1137/1137 [==============================] - 1s 545us/step - loss: 14771.5489 - val_loss: 25961.4815\n",
      "Epoch 1093/1200\n",
      "1137/1137 [==============================] - 1s 582us/step - loss: 14884.8092 - val_loss: 27506.9443\n",
      "Epoch 1094/1200\n",
      "1137/1137 [==============================] - 1s 596us/step - loss: 15144.9103 - val_loss: 27086.7021\n",
      "Epoch 1095/1200\n",
      "1137/1137 [==============================] - 1s 568us/step - loss: 14596.1734 - val_loss: 25400.5403\n",
      "Epoch 1096/1200\n",
      "1137/1137 [==============================] - 1s 571us/step - loss: 14139.3052 - val_loss: 27690.2191\n",
      "Epoch 1097/1200\n",
      "1137/1137 [==============================] - 1s 540us/step - loss: 15837.4160 - val_loss: 26751.3835\n",
      "Epoch 1098/1200\n",
      "1137/1137 [==============================] - 1s 602us/step - loss: 14607.2063 - val_loss: 26320.1084\n",
      "Epoch 1099/1200\n",
      "1137/1137 [==============================] - 1s 595us/step - loss: 15181.4757 - val_loss: 26191.0941\n",
      "Epoch 1100/1200\n",
      "1137/1137 [==============================] - 1s 584us/step - loss: 15306.7233 - val_loss: 25830.2466\n",
      "Epoch 1101/1200\n",
      "1137/1137 [==============================] - 1s 568us/step - loss: 14787.9216 - val_loss: 26488.6828\n",
      "Epoch 1102/1200\n",
      "1137/1137 [==============================] - 1s 596us/step - loss: 14836.8837 - val_loss: 25667.8966\n",
      "Epoch 1103/1200\n",
      "1137/1137 [==============================] - 1s 558us/step - loss: 14185.4056 - val_loss: 27209.8927\n",
      "Epoch 1104/1200\n",
      "1137/1137 [==============================] - 1s 568us/step - loss: 14874.7715 - val_loss: 25904.3294\n",
      "Epoch 1105/1200\n",
      "1137/1137 [==============================] - 1s 537us/step - loss: 14837.4671 - val_loss: 26653.5828\n",
      "Epoch 1106/1200\n",
      "1137/1137 [==============================] - 1s 605us/step - loss: 15075.8564 - val_loss: 26255.0059\n",
      "Epoch 1107/1200\n",
      "1137/1137 [==============================] - 1s 553us/step - loss: 14978.4938 - val_loss: 25963.9174\n",
      "Epoch 1108/1200\n",
      "1137/1137 [==============================] - 1s 586us/step - loss: 14745.2510 - val_loss: 25882.1225\n",
      "Epoch 1109/1200\n",
      "1137/1137 [==============================] - 1s 573us/step - loss: 15631.3974 - val_loss: 25885.9727\n",
      "Epoch 1110/1200\n",
      "1137/1137 [==============================] - 1s 508us/step - loss: 14585.7398 - val_loss: 26546.4232\n",
      "Epoch 1111/1200\n",
      "1137/1137 [==============================] - 1s 545us/step - loss: 15441.4719 - val_loss: 26262.9125\n",
      "Epoch 1112/1200\n",
      "1137/1137 [==============================] - 1s 551us/step - loss: 15983.6941 - val_loss: 25269.0336\n",
      "Epoch 1113/1200\n",
      "1137/1137 [==============================] - 1s 519us/step - loss: 14395.6489 - val_loss: 25733.4119\n",
      "Epoch 1114/1200\n",
      "1137/1137 [==============================] - 1s 541us/step - loss: 14818.3779 - val_loss: 25744.0209\n",
      "Epoch 1115/1200\n",
      "1137/1137 [==============================] - 1s 541us/step - loss: 14644.6339 - val_loss: 26399.9194\n",
      "Epoch 1116/1200\n",
      "1137/1137 [==============================] - 1s 582us/step - loss: 14198.0655 - val_loss: 25703.9206\n",
      "Epoch 1117/1200\n",
      "1137/1137 [==============================] - 1s 530us/step - loss: 15303.2381 - val_loss: 25791.1625\n",
      "Epoch 1118/1200\n",
      "1137/1137 [==============================] - 1s 537us/step - loss: 15215.9886 - val_loss: 25696.9761\n",
      "Epoch 1119/1200\n",
      "1137/1137 [==============================] - 1s 576us/step - loss: 14450.4737 - val_loss: 26845.2438\n",
      "Epoch 1120/1200\n",
      "1137/1137 [==============================] - 1s 545us/step - loss: 14907.9228 - val_loss: 26927.2955\n",
      "Epoch 1121/1200\n",
      "1137/1137 [==============================] - 1s 540us/step - loss: 14819.4628 - val_loss: 27777.3635\n",
      "Epoch 1122/1200\n",
      "1137/1137 [==============================] - 1s 553us/step - loss: 14375.8175 - val_loss: 27361.0853\n",
      "Epoch 1123/1200\n",
      "1137/1137 [==============================] - 1s 588us/step - loss: 14406.5020 - val_loss: 26522.7861\n",
      "Epoch 1124/1200\n",
      "1137/1137 [==============================] - 1s 578us/step - loss: 14453.2976 - val_loss: 25658.4407\n",
      "Epoch 1125/1200\n",
      "1137/1137 [==============================] - 1s 558us/step - loss: 14836.7677 - val_loss: 27579.8984\n",
      "Epoch 1126/1200\n",
      "1137/1137 [==============================] - 1s 547us/step - loss: 15579.3958 - val_loss: 25696.0802\n",
      "Epoch 1127/1200\n",
      "1137/1137 [==============================] - 1s 546us/step - loss: 14709.8307 - val_loss: 27750.5532\n",
      "Epoch 1128/1200\n",
      "1137/1137 [==============================] - 1s 582us/step - loss: 15663.2088 - val_loss: 28777.6702\n",
      "Epoch 1129/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 1s 529us/step - loss: 14521.6656 - val_loss: 26274.1859\n",
      "Epoch 1130/1200\n",
      "1137/1137 [==============================] - 1s 557us/step - loss: 14818.3061 - val_loss: 25782.2273\n",
      "Epoch 1131/1200\n",
      "1137/1137 [==============================] - 1s 573us/step - loss: 14539.6854 - val_loss: 29045.1112\n",
      "Epoch 1132/1200\n",
      "1137/1137 [==============================] - 1s 599us/step - loss: 14513.3440 - val_loss: 26114.3362\n",
      "Epoch 1133/1200\n",
      "1137/1137 [==============================] - 1s 559us/step - loss: 14332.1713 - val_loss: 25991.6160\n",
      "Epoch 1134/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 14747.2613 - val_loss: 26542.4702\n",
      "Epoch 1135/1200\n",
      "1137/1137 [==============================] - 1s 575us/step - loss: 15087.7674 - val_loss: 26253.5417\n",
      "Epoch 1136/1200\n",
      "1137/1137 [==============================] - 1s 572us/step - loss: 14627.7665 - val_loss: 25722.1377\n",
      "Epoch 1137/1200\n",
      "1137/1137 [==============================] - 1s 538us/step - loss: 14854.0549 - val_loss: 26081.5920\n",
      "Epoch 1138/1200\n",
      "1137/1137 [==============================] - 1s 529us/step - loss: 13988.9871 - val_loss: 26223.8733\n",
      "Epoch 1139/1200\n",
      "1137/1137 [==============================] - 1s 561us/step - loss: 15070.3310 - val_loss: 26049.4981\n",
      "Epoch 1140/1200\n",
      "1137/1137 [==============================] - 1s 528us/step - loss: 15483.2159 - val_loss: 26123.2452\n",
      "Epoch 1141/1200\n",
      "1137/1137 [==============================] - 1s 524us/step - loss: 14157.3316 - val_loss: 25842.1862\n",
      "Epoch 1142/1200\n",
      "1137/1137 [==============================] - 1s 533us/step - loss: 14049.9166 - val_loss: 27135.4476\n",
      "Epoch 1143/1200\n",
      "1137/1137 [==============================] - 1s 530us/step - loss: 14495.8607 - val_loss: 27662.0377\n",
      "Epoch 1144/1200\n",
      "1137/1137 [==============================] - 1s 521us/step - loss: 15268.4319 - val_loss: 26587.4712\n",
      "Epoch 1145/1200\n",
      "1137/1137 [==============================] - 1s 541us/step - loss: 14424.7989 - val_loss: 26119.1864\n",
      "Epoch 1146/1200\n",
      "1137/1137 [==============================] - 1s 543us/step - loss: 15189.3315 - val_loss: 26211.9322\n",
      "Epoch 1147/1200\n",
      "1137/1137 [==============================] - 1s 541us/step - loss: 15253.3926 - val_loss: 28770.1067\n",
      "Epoch 1148/1200\n",
      "1137/1137 [==============================] - 1s 516us/step - loss: 14520.5518 - val_loss: 28214.0538\n",
      "Epoch 1149/1200\n",
      "1137/1137 [==============================] - 1s 567us/step - loss: 15158.6761 - val_loss: 25946.8908\n",
      "Epoch 1150/1200\n",
      "1137/1137 [==============================] - 1s 543us/step - loss: 15029.0925 - val_loss: 25959.1348\n",
      "Epoch 1151/1200\n",
      "1137/1137 [==============================] - 1s 599us/step - loss: 14569.6193 - val_loss: 26765.7702\n",
      "Epoch 1152/1200\n",
      "1137/1137 [==============================] - 1s 593us/step - loss: 14127.8936 - val_loss: 28377.5165\n",
      "Epoch 1153/1200\n",
      "1137/1137 [==============================] - 1s 537us/step - loss: 14862.6099 - val_loss: 25042.1205\n",
      "Epoch 1154/1200\n",
      "1137/1137 [==============================] - 1s 520us/step - loss: 14880.3511 - val_loss: 27230.4049\n",
      "Epoch 1155/1200\n",
      "1137/1137 [==============================] - 1s 549us/step - loss: 15261.0714 - val_loss: 26061.0029\n",
      "Epoch 1156/1200\n",
      "1137/1137 [==============================] - 1s 536us/step - loss: 14552.7574 - val_loss: 26442.3326\n",
      "Epoch 1157/1200\n",
      "1137/1137 [==============================] - 1s 550us/step - loss: 14372.9863 - val_loss: 27348.3208\n",
      "Epoch 1158/1200\n",
      "1137/1137 [==============================] - 1s 537us/step - loss: 14172.9464 - val_loss: 26056.4703\n",
      "Epoch 1159/1200\n",
      "1137/1137 [==============================] - 1s 596us/step - loss: 14196.7256 - val_loss: 25622.1736\n",
      "Epoch 1160/1200\n",
      "1137/1137 [==============================] - 1s 543us/step - loss: 15598.0555 - val_loss: 26072.7589\n",
      "Epoch 1161/1200\n",
      "1137/1137 [==============================] - 1s 538us/step - loss: 14568.9314 - val_loss: 25539.0384\n",
      "Epoch 1162/1200\n",
      "1137/1137 [==============================] - 1s 561us/step - loss: 14073.1554 - val_loss: 26487.2098\n",
      "Epoch 1163/1200\n",
      "1137/1137 [==============================] - 1s 531us/step - loss: 14616.8288 - val_loss: 26263.1745\n",
      "Epoch 1164/1200\n",
      "1137/1137 [==============================] - 1s 546us/step - loss: 14871.4835 - val_loss: 27634.1417\n",
      "Epoch 1165/1200\n",
      "1137/1137 [==============================] - 1s 528us/step - loss: 14791.8663 - val_loss: 26843.5310\n",
      "Epoch 1166/1200\n",
      "1137/1137 [==============================] - 1s 540us/step - loss: 14802.9876 - val_loss: 26334.4604\n",
      "Epoch 1167/1200\n",
      "1137/1137 [==============================] - 1s 536us/step - loss: 15026.2397 - val_loss: 25348.3942\n",
      "Epoch 1168/1200\n",
      "1137/1137 [==============================] - 1s 540us/step - loss: 14203.2445 - val_loss: 25470.3759\n",
      "Epoch 1169/1200\n",
      "1137/1137 [==============================] - 1s 538us/step - loss: 14528.2069 - val_loss: 28076.1751\n",
      "Epoch 1170/1200\n",
      "1137/1137 [==============================] - 1s 583us/step - loss: 14705.2205 - val_loss: 25742.5066\n",
      "Epoch 1171/1200\n",
      "1137/1137 [==============================] - 1s 628us/step - loss: 14869.1088 - val_loss: 25845.0002\n",
      "Epoch 1172/1200\n",
      "1137/1137 [==============================] - 1s 585us/step - loss: 14350.6567 - val_loss: 26754.6212\n",
      "Epoch 1173/1200\n",
      "1137/1137 [==============================] - 1s 546us/step - loss: 14676.1443 - val_loss: 25890.1821\n",
      "Epoch 1174/1200\n",
      "1137/1137 [==============================] - 1s 541us/step - loss: 14234.1269 - val_loss: 26186.4938\n",
      "Epoch 1175/1200\n",
      "1137/1137 [==============================] - 1s 567us/step - loss: 14749.4332 - val_loss: 29206.4138\n",
      "Epoch 1176/1200\n",
      "1137/1137 [==============================] - 1s 531us/step - loss: 14600.2544 - val_loss: 25882.6372\n",
      "Epoch 1177/1200\n",
      "1137/1137 [==============================] - 1s 566us/step - loss: 15331.7402 - val_loss: 27835.0357\n",
      "Epoch 1178/1200\n",
      "1137/1137 [==============================] - 1s 591us/step - loss: 14737.3002 - val_loss: 27773.2270\n",
      "Epoch 1179/1200\n",
      "1137/1137 [==============================] - 1s 527us/step - loss: 14739.3228 - val_loss: 25884.4906\n",
      "Epoch 1180/1200\n",
      "1137/1137 [==============================] - 1s 545us/step - loss: 14763.8847 - val_loss: 25500.9373\n",
      "Epoch 1181/1200\n",
      "1137/1137 [==============================] - 1s 561us/step - loss: 13894.7860 - val_loss: 25703.9236\n",
      "Epoch 1182/1200\n",
      "1137/1137 [==============================] - 1s 539us/step - loss: 14566.4548 - val_loss: 26032.3669\n",
      "Epoch 1183/1200\n",
      "1137/1137 [==============================] - 1s 581us/step - loss: 13895.9519 - val_loss: 26615.3937\n",
      "Epoch 1184/1200\n",
      "1137/1137 [==============================] - 1s 551us/step - loss: 14707.2859 - val_loss: 26242.0087\n",
      "Epoch 1185/1200\n",
      "1137/1137 [==============================] - 1s 576us/step - loss: 13858.0070 - val_loss: 25690.8290\n",
      "Epoch 1186/1200\n",
      "1137/1137 [==============================] - 1s 525us/step - loss: 14125.0791 - val_loss: 25811.2263\n",
      "Epoch 1187/1200\n",
      "1137/1137 [==============================] - 1s 597us/step - loss: 14628.5230 - val_loss: 26336.7019\n",
      "Epoch 1188/1200\n",
      "1137/1137 [==============================] - 1s 534us/step - loss: 15438.4196 - val_loss: 26067.9594\n",
      "Epoch 1189/1200\n",
      "1137/1137 [==============================] - 1s 578us/step - loss: 14119.3681 - val_loss: 27280.9891\n",
      "Epoch 1190/1200\n",
      "1137/1137 [==============================] - 1s 597us/step - loss: 15203.0772 - val_loss: 25743.4432\n",
      "Epoch 1191/1200\n",
      "1137/1137 [==============================] - 1s 596us/step - loss: 14489.6159 - val_loss: 25646.1669\n",
      "Epoch 1192/1200\n",
      "1137/1137 [==============================] - 1s 614us/step - loss: 14266.0490 - val_loss: 25605.1956\n",
      "Epoch 1193/1200\n",
      "1137/1137 [==============================] - 1s 623us/step - loss: 14308.4409 - val_loss: 28850.4093\n",
      "Epoch 1194/1200\n",
      "1137/1137 [==============================] - 1s 598us/step - loss: 15113.3758 - val_loss: 25685.1455\n",
      "Epoch 1195/1200\n",
      "1137/1137 [==============================] - 1s 561us/step - loss: 14375.0302 - val_loss: 25821.7473\n",
      "Epoch 1196/1200\n",
      "1137/1137 [==============================] - 1s 593us/step - loss: 13976.6750 - val_loss: 26391.7276\n",
      "Epoch 1197/1200\n",
      "1137/1137 [==============================] - 1s 543us/step - loss: 14055.8355 - val_loss: 25896.7256\n",
      "Epoch 1198/1200\n",
      "1137/1137 [==============================] - 1s 547us/step - loss: 14339.3332 - val_loss: 27733.4585\n",
      "Epoch 1199/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 1s 526us/step - loss: 14203.3856 - val_loss: 25818.4382\n",
      "Epoch 1200/1200\n",
      "1137/1137 [==============================] - 1s 538us/step - loss: 14497.0919 - val_loss: 25735.0952\n"
     ]
    }
   ],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu',input_dim = 175))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim = 25, init = 'he_uniform',activation='relu'))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "classifier.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu'))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'he_uniform'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(loss=root_mean_squared_error, optimizer='Adamax')\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model_history=classifier.fit(X_train.values, y_train.values,validation_split=0.20, batch_size = 10, nb_epoch = 1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_pred=classifier.predict(df_Test.drop(['SalePrice'],axis=1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Sample Submission file and Submit using ANN\n",
    "pred=pd.DataFrame(ann_pred)\n",
    "sub_df=pd.read_csv(r'D:\\Manipal Data Science\\Kaggle\\t\\sample_submission.csv')\n",
    "datasets=pd.concat([sub_df['Id'],pred],axis=1)\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>139293.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112697.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140688.296875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140858.156250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>266450.187500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "0  139293.546875\n",
       "1  112697.468750\n",
       "2  140688.296875\n",
       "3  140858.156250\n",
       "4  266450.187500"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow1",
   "language": "python",
   "name": "tensorflow1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
